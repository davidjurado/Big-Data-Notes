{"paragraphs":[{"text":"%md\n#¿Qué es big data?\n\nExisten muchas definiciones de big data, una de las más populares es la de Gartner:\n\n*\"Big Data son activos de información de gran volumen, alta velocidad y gran variedad, que demandan formas rentables e innovadoras de procesamiento, lo que permiten un mejor conocimiento, toma de decisiones y automatización de procesos\"*, [Fuente](https://www.gartner.com/it-glossary/big-data).\n\nDicho de otro modo, el big data está formado por conjuntos de datos de mayor tamaño y más complejos, especialmente procedentes de nuevas fuentes de datos. Estos conjuntos de datos son tan voluminosos que el software de procesamiento de datos convencional sencillamente no puede gestionarlos. Sin embargo, estos volúmenes masivos de datos pueden utilizarse para abordar problemas empresariales que antes no hubiera sido posible solucionar.\n\n###Las tres V's de big data\n\n* **Volumen**: La cantidad de datos importa. Con big data, deberá procesar grandes volúmenes de datos no estructurados de baja densidad. Puede tratarse de datos de valor desconocido, como feeds de datos de Twitter, flujos de clics de una página web o aplicación para móviles, o equipo con sensores. Para algunas organizaciones, esto puede suponer decenas de terabytes de datos. Para otras, incluso cientos de petabytes.\n\n* **Velocidad**: La velocidad es el ritmo al que se reciben los datos y (posiblemente) al que se aplica alguna acción. La mayor velocidad de los datos normalmente se transmite directamente a la memoria, en vez de escribirse en un disco. Algunos productos inteligentes habilitados para Internet funcionan en tiempo real o prácticamente en tiempo real y requieren una evaluación y actuación en tiempo real. \n\n* **Variedad**: La variedad hace referencia a los diversos tipos de datos disponibles. Los tipos de datos convencionales eran estructurados y podían organizarse claramente en una base de datos relacional. Con el auge del big data, los datos se presentan en nuevos tipos de datos no estructurados. Los tipos de datos no estructurados y semiestructurados, como el texto, audio o vídeo, requieren de un preprocesamiento adicional para poder obtener significado y habilitar los metadatos.\n\n###El valor y veracidad de big data\n\nEn los últimos años, han surgido otras \"dos V\": valor y veracidad.\n\nLos datos poseen un valor intrínseco. Sin embargo, no tienen ninguna utilidad hasta que dicho valor se descubre. Resulta igualmente importante: ¿cuál es la veracidad de sus datos y cuánto puede confiar en ellos?\n\nHoy en día, el big data se ha convertido en un activo crucial. Piense en algunas de las mayores empresas tecnológicas del mundo. Gran parte del valor que ofrecen procede de sus datos, que analizan constantemente para generar una mayor eficiencia y desarrollar nuevos productos.\n\nAvances tecnológicos recientes han reducido exponencialmente el coste del almacenamiento y la computación de datos, haciendo que almacenar datos resulte más fácil y barato que nunca. Actualmente, con un mayor volumen de big data más barato y accesible, puede tomar decisiones empresariales más acertadas y precisas.\n\nIdentificar el valor del big data no pasa solo por analizarlo (que es ya una ventaja en sí misma). Se trata de todo un proceso de descubrimiento que requiere que los analistas, usuarios empresariales y ejecutivos se planteen las preguntas correctas, identifiquen patrones, tomen decisiones informadas y predigan comportamientos.\n\n###La historia de big data\n\nSi bien el concepto \"big data\" en sí mismo es relativamente nuevo, los orígenes de los grandes conjuntos de datos se remontan a las décadas de 1960 y 1970, donde se sitúan los albores de este universo con los primeros centros de datos y el desarrollo de las bases de datos relacionales.\n\nAlrededor de 2005, la gente empezó a darse cuenta de la cantidad de datos que generaban los usuarios a través de Facebook, YouTube y otros servicios online. Ese mismo año, se desarrollaría Hadoop, un marco de código abierto creado específicamente para almacenar y analizar grandes conjuntos de datos. En esta época, también empezaría a adquirir popularidad NoSQL.\n\nEl desarrollo de Framewoks de código abierto tales como Hadoop (y, más recientemente, Spark) sería esencial para el crecimiento del big data, pues estos hacían que el big data resultase más fácil de usar y más barato de almacenar. En los años siguientes, el volumen de big data se ha disparado. Los usuarios continúan generando enormes cantidades de datos, pero ahora los humanos no son los únicos que lo hacen.\n\nCon la llegada del Internet de las cosas (IoT), hay un mayor número de objetos y dispositivos conectados a Internet que generan datos sobre patrones de uso de los clientes y rendimiento de los productos. El surgimiento del aprendizaje automático ha producido aún más datos.\n\nAunque el big data ha llegado lejos, su utilidad no ha hecho más que empezar. El Cloud Computing ha ampliado aún más las posibilidades del big data. La nube ofrece una escalabilidad realmente elástica, donde los desarrolladores pueden simplemente agilizar clústeres ad hoc para probar un subconjunto de datos.\n\n###Ventajas de big data y de la analítica de datos\n\n* El big data le permite obtener respuestas más completas, ya que dispone de mayor cantidad de información.\n* La disponibilidad de respuestas más completas significa una mayor fiabilidad de los datos, lo que implica un enfoque completamente distinto a la hora de abordar problemas.\n\n\n###Casos de uso de big data\n\nEl big data puede ayudarle a abordar una serie de actividades empresariales, desde la experiencia de cliente hasta la analítica. A continuación, recopilamos algunas de ellas\n\n####Desarrollo de productos\nEmpresas como Netflix y Procter & Gamble usan big data para prever la demanda de los clientes. Construyen modelos predictivos para nuevos productos y servicios clasificando atributos clave de productos anteriores y actuales, y modelando la relación entre dichos atributos y el éxito comercial de las ofertas. Además, P&G utiliza los datos y la analítica de grupos de interés, redes sociales, mercados de prueba y avances de salida en tiendas para planificar, producir y lanzar nuevos productos.\n\n####Mantenimiento predictivo\nLos factores capaces de predecir fallos mecánicos pueden estar profundamente ocultos entre datos estructurados (año del equipo, marca o modelo de una máquina) o entre datos no estructurados que cubren millones de entradas de registros, datos de sensores, mensajes de error y temperaturas de motor. Al analizar estos indicadores de problemas potenciales antes de que estos se produzcan, las organizaciones pueden implantar el mantenimiento de una forma más rentable y optimizar el tiempo de servicio de componentes y equipos.\n\n####Experiencia del cliente\nLa carrera para conseguir clientes ha comenzado. Disponer de una vista clara de la experiencia del cliente es más posible que nunca. El big data le permite recopilar datos de redes sociales, visitas a páginas web, registros de llamadas y otras fuentes de datos para mejorar la experiencia de interacción, así como maximizar el valor ofrecido. Empiece a formular ofertas personalizadas, reducir las tasas de abandono de los clientes y gestionar las incidencias de manera proactiva.\n\n####Fraude y conformidad\nEn lo que a seguridad se refiere, no se enfrenta a simples piratas informáticos deshonestos, sino a equipos completos de expertos. Los contextos de seguridad y requisitos de conformidad están en constante evolución. El big data le ayuda a identificar patrones en los datos que pueden ser indicativos de fraude, al tiempo que concentra grandes volúmenes de información para agilizar la generación de informes normativos.\n\n####Aprendizaje automático (Machine Learning)\nEl aprendizaje automático es actualmente un tema de gran actualidad. Los datos —concretamente big data— son uno de los motivos de que así sea. Ahora, en lugar de programarse, las máquinas pueden aprender. Esto es posible gracias a la disponibilidad de big data para crear modelos de aprendizaje automático.\n\n####Eficiencia operativa\nPuede que la eficiencia operativa no sea el aspecto más destacado en los titulares, pero es el área en que big data tiene un mayor impacto. El big data le permite analizar y evaluar la producción, la opinión de los clientes, las devoluciones y otros factores para reducir las situaciones de falta de stock y anticipar la demanda futura. El big data también puede utilizarse para mejorar la toma de decisiones en función de la demanda de mercado en cada momento.\n\n####Impulso de la innovación\nEl big data puede ayudarle a innovar mediante el estudio de las interdependencias entre seres humanos, instituciones, entidades y procesos, y, posteriormente, mediante la determinación de nuevas formas de usar dicha información. Utilice las perspectivas que le ofrecen los datos para mejorar sus decisiones financieras y consideraciones de planificación. Estudie las tendencias y lo que desean los clientes para ofrecer nuevos productos y servicios. Implante políticas de precios dinámicas. Las posibilidades son infinitas.\n\n###Desafíos de big data\n\nSi bien es cierto que el big data promete mucho, también se enfrenta a desafíos.\n\nEn primer lugar, el big data se caracteriza por su gran tamaño. Aunque se han desarrollado nuevas tecnologías para el almacenamiento de datos, el volumen de datos duplica su tamaño cada dos años aproximadamente. Las organizaciones continúan esforzándose por mantener el ritmo de crecimiento de sus datos y por encontrar formas de almacenarlos eficazmente.\n\nPero no basta con almacenar los datos. Para ser de algún valor, los datos deben poder utilizarse, y esto depende de su conservación. Disponer de datos limpios —es decir, datos relevantes para el cliente y organizados de tal modo que permitan un análisis significativo— requiere una gran cantidad de trabajo. Los científicos de datos dedican entre un 50 y un 80 por ciento de su tiempo a seleccionar y preparar los datos antes de que estos puedan utilizarse.\n\nPor último, la tecnología de big data cambia a un ritmo rápido. Hace unos años, Apache Hadoop era la tecnología más conocida utilizada para gestionar big data. Más tarde, en 2014, entraría en juego Apache Spark. Hoy en día, el enfoque óptimo parece ser una combinación de ambos frameworks. Mantenerse al día en cuanto a tecnología de big data supone un desafío constante.\n\n###¿Cómo funciona big data?\n\nEl big data le aporta nuevas perspectivas que abren paso a nuevas oportunidades y modelos de negocio. Iniciarse en ello requiere de tres acciones clave:\n\n####Integrar\n\nEl big data concentra datos de numerosas fuentes y aplicaciones distintas. Los mecanismos de integración de datos convencionales, tales como ETL (extract, transform, load [extraer, transformar, cargar]), generalmente no están a la altura en dicha tarea. Analizar conjuntos de big data de uno o más terabytes, o incluso petabytes, de tamaño requiere de nuevas estrategias y tecnologías.\n\nDurante la integración, es necesario incorporar los datos, procesarlos y asegurarse de que estén formateados y disponibles de tal forma que los analistas empresariales puedan empezar a utilizarlos.\n\n####Gestionar\n\nEl big data requiere almacenamiento. Su solución de almacenamiento puede residir en la nube, on premise o ambas. Puede almacenar sus datos de cualquier forma que desee e incorporar los requisitos de procesamiento de su preferencia y los motores de procesamiento necesarios a dichos conjuntos de datos on-demand. Muchas personas eligen su solución de almacenamiento en función de dónde residan sus datos en cada momento. La nube está aumentando progresivamente su popularidad porque es compatible con sus requisitos tecnológicos actuales y porque le permite incorporar recursos a medida que los necesita.\n\n\n####Analizar\n\nLa inversión en big data se rentabiliza en cuanto se analizan y utilizan los datos. Adquiera una nueva claridad con un análisis visual de sus diversos conjuntos de datos. Continúe explorando los datos para realizar nuevos descubrimientos. Comparta sus hallazgos con otras personas. Construya modelos de datos con aprendizaje automático e inteligencia artificial. Ponga sus datos a trabajar.\n\n###Mejores prácticas de big data\n\nPara ayudarle en su transición a big data, hemos recopilado una serie de mejores prácticas que debe tener en cuenta. A continuación, detallamos nuestras pautas para crear con éxito una base de big data.\n\n\n####Alinear big data con objetivos empresariales específicos \t\n\nLa disponibilidad de conjuntos de datos más amplios le permite realizar nuevos hallazgos. A tal efecto, es importante basar las nuevas inversiones en habilidades, organización o infraestructura con un marcado contexto empresarial para garantizar la constancia en la financiación e inversión en proyectos. Para determinar si se encuentra en el camino correcto, pregúntese en qué medida el big data respalda y habilita sus principales prioridades empresariales y de TI. Algunos ejemplos incluyen entender cómo filtrar los registros web para comprender el comportamiento del comercio electrónico, extraer el sentimiento de las redes sociales y de las interacciones de atención al cliente, así como entender los métodos de correlación estadística y su relevancia para los datos de clientes, productos, fabricación e ingeniería.\n\n####Facilite la escasez de habilidades con estándares y administración \t\n\nUno de los mayores obstáculos del big data es la escasez de habilidades. Puede mitigar el riesgo asegurándose de incorporar a su programa de administración de TI tecnologías, consideraciones y decisiones relativas a big data. Normalizar su enfoque le permitirá gestionar los costes y aprovechar los recursos. Las organizaciones que implanten soluciones y estrategias de big data deben evaluar sus necesidades de habilidades de forma temprana y frecuente, e identificar de manera proactiva las posibles carencias de habilidades. Esto puede lograrse mediante la impartición de formación o la formación cruzada entre recursos existentes, la contratación de nuevos recursos y el uso de empresas de consultoría.\n\n####Optimizar la transferencia de conocimientos con un centro de excelencia \t\n\nUtilice un enfoque basado en un centro de excelencia para compartir conocimientos, supervisar el control y gestionar las comunicaciones de proyectos. Tanto si el big data es una inversión nueva o en expansión, los costes directos e indirectos pueden distribuirse en toda la empresa. Utilizar este enfoque puede contribuir a incrementar las capacidades de big data y la madurez del conjunto de la arquitectura de información de una forma más sistemática y estructurada.\n\n####La principal ventaja reside en alinear los datos estructurados y no estructurados \t\n\nAnalizar el big data de forma aislada sin duda aporta valor. Sin embargo, puede obtener una perspectiva empresarial aún más valiosa relacionando e integrando el big data de baja densidad con los datos estructurados que ya usa actualmente.\n\nTanto si está recopilando big data de clientes, de productos, de equipos o ambientales, el objetivo es añadir puntos de datos más relevantes a sus resúmenes maestros y analíticos, lo que le permitirá obtener mejores conclusiones. Por ejemplo, existe una diferencia en distinguir la percepción de todos los clientes de la de solo sus mejores clientes. Por eso, muchos consideran que big data constituye una extensión integral de sus capacidades existentes de inteligencia empresarial, de su plataforma de almacenamiento de datos y de su arquitectura de información.\n\nTenga en cuenta que los modelos y procesos analíticos de big data pueden ser tanto humanos como automáticos. Las capacidades de análisis de big data incluyen estadísticas, análisis especiales, semántica, detección interactiva y visualización. Mediante el uso de modelos analíticos, puede relacionar distintos tipos y fuentes de datos para realizar asociaciones y hallazgos significativos.\n\n####Planificar el laboratorio de hallazgos en pro del rendimiento \t\n\nEl concepto \"hallazgo\" implica que los datos no siempre se obtienen directamente. En ocasiones, ni siquiera sabemos qué estamos buscando. Eso es de esperar. La dirección y los equipos de TI deben respaldar esta “falta de dirección” o “falta de claridad en los requisitos.”\n\nAl mismo tiempo, es importante que analistas y científicos de datos colaboren estrechamente con la empresa para entender las principales necesidades y carencias de conocimientos de la empresa. Para incorporar el estudio interactivo de los datos y la experimentación de algoritmos estadísticos, necesita contar con áreas de trabajo de alto rendimiento. Asegúrese de que los entornos de pruebas (sandbox) tienen la potencia necesaria y están correctamente gobernados.\n\n####Alineación con el modelo operativo en la nube \t\n\nLos usuarios y procesos de big data requieren acceso a una amplia variedad de recursos de experimentación reiterativa y ejecución de tareas de producción. Una solución de big data incluye todos los ámbitos de los datos, incluidas transacciones, datos principales, datos de referencia y datos resumidos. Los entornos de pruebas (sandboxes) analíticos deben crearse on-demand. La gestión de recursos es fundamental para garantizar el control de todo el flujo de datos, incluido el procesamiento previo y posterior, la integración, el resumen dentro de la base de datos y la creación de modelos analíticos. Disponer de una estrategia bien definida de aprovisionamiento y seguridad en la nube pública y privada es fundamental para respaldar estos requisitos cambiantes.\n\n\n\n\n\n###¿Qué ha dado lugar a la prominencia de big data?\n\n####escenarios\n\nEscenarios donde se producen grandes volúmenes de datos, el clásico ejemplo es internet (redes sociales, blogs, imágenes, videos, etc), hay otros escenarios como la cadena de suministro, que se encarga de todo el inventario de almacenes a niveles enormes, incluso las torres de celulares producen grandes cantidades de información, incluso antes, los códigos upc, que son los códigos de barra de productos en almacenes también han producido grandes cantidades de datos.\n\n####¿Qué es lo que ha permitido la llegada big data?\nBig data es compatible con hardware básico (servidores baratos, discos baratos), reducción en costos de almacenamiento, muchas de las tecnologías big data se basa en software de código abierto, la economía web (migración de todo tipo de negocios ha generado una necesidad de generar y consumir datos)\n\n###¿que se puede hacer con big data?\n\nAnálisis de clicks, patrones de compra\nAnálisis de sentimientos\nDetección de fraudes\nEstrategias de inversión (ML)\nInvestigaciones sobre salud\nPredicción y prevención de fallas de equipos\n\n###Definiendo más específicamente por aspectos\n\n*Tamaño: No hay un estándar que diga que cantidad de datos se necesita para que sea considerada big data, pero si míralos las tecnologías que no pertenecen a big data se podría decir que a partir del rango de cientos de terabytes, considerado el umbral, se comienza a requerir tecnologías big data porque las tradicionales ya no funcionan bien, pedabyte es 1024 terabytes.\n\n3s V's: \n* Volumen: Se refiere a la cantidad de datos.\n* Velocidad: Que tan rápido esos datos están llegando y que tan rápido se tiene que procesar\n* Variedad: se refiere a la estructura de los datos, la mayoria de datos son datos no relacionales (organizados en filas o columnas)\n\n**Big data es demasiado grande para bases de datos OLTP (OnLine Transaction Processing)**\n\nUsa procesamiento distribuido (o en paralelo), porque la idea es que si tienen un recurso de big data lo que se quiere haces es dividir los datos en partes más pequeñas y que sean procesados a través de un cluster\n\n\n[![](http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png)](http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png \"Big Data Landscape 2018\")\n","user":"anonymous","dateUpdated":"2018-06-27T21:48:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>¿Qué es big data?</h1>\n<p>Existen muchas definiciones de big data, una de las más populares es la de Gartner:</p>\n<p><em>&ldquo;Big Data son activos de información de gran volumen, alta velocidad y gran variedad, que demandan formas rentables e innovadoras de procesamiento, lo que permiten un mejor conocimiento, toma de decisiones y automatización de procesos&rdquo;</em>, <a href=\"https://www.gartner.com/it-glossary/big-data\">Fuente</a>.</p>\n<p>Dicho de otro modo, el big data está formado por conjuntos de datos de mayor tamaño y más complejos, especialmente procedentes de nuevas fuentes de datos. Estos conjuntos de datos son tan voluminosos que el software de procesamiento de datos convencional sencillamente no puede gestionarlos. Sin embargo, estos volúmenes masivos de datos pueden utilizarse para abordar problemas empresariales que antes no hubiera sido posible solucionar.</p>\n<h3>Las tres V's de big data</h3>\n<ul>\n<li><p><strong>Volumen</strong>: La cantidad de datos importa. Con big data, deberá procesar grandes volúmenes de datos no estructurados de baja densidad. Puede tratarse de datos de valor desconocido, como feeds de datos de Twitter, flujos de clics de una página web o aplicación para móviles, o equipo con sensores. Para algunas organizaciones, esto puede suponer decenas de terabytes de datos. Para otras, incluso cientos de petabytes.</p>\n</li>\n<li><p><strong>Velocidad</strong>: La velocidad es el ritmo al que se reciben los datos y (posiblemente) al que se aplica alguna acción. La mayor velocidad de los datos normalmente se transmite directamente a la memoria, en vez de escribirse en un disco. Algunos productos inteligentes habilitados para Internet funcionan en tiempo real o prácticamente en tiempo real y requieren una evaluación y actuación en tiempo real.</p>\n</li>\n<li><p><strong>Variedad</strong>: La variedad hace referencia a los diversos tipos de datos disponibles. Los tipos de datos convencionales eran estructurados y podían organizarse claramente en una base de datos relacional. Con el auge del big data, los datos se presentan en nuevos tipos de datos no estructurados. Los tipos de datos no estructurados y semiestructurados, como el texto, audio o vídeo, requieren de un preprocesamiento adicional para poder obtener significado y habilitar los metadatos.</p>\n</li>\n</ul>\n<h3>El valor y veracidad de big data</h3>\n<p>En los últimos años, han surgido otras &ldquo;dos V&rdquo;: valor y veracidad.</p>\n<p>Los datos poseen un valor intrínseco. Sin embargo, no tienen ninguna utilidad hasta que dicho valor se descubre. Resulta igualmente importante: ¿cuál es la veracidad de sus datos y cuánto puede confiar en ellos?</p>\n<p>Hoy en día, el big data se ha convertido en un activo crucial. Piense en algunas de las mayores empresas tecnológicas del mundo. Gran parte del valor que ofrecen procede de sus datos, que analizan constantemente para generar una mayor eficiencia y desarrollar nuevos productos.</p>\n<p>Avances tecnológicos recientes han reducido exponencialmente el coste del almacenamiento y la computación de datos, haciendo que almacenar datos resulte más fácil y barato que nunca. Actualmente, con un mayor volumen de big data más barato y accesible, puede tomar decisiones empresariales más acertadas y precisas.</p>\n<p>Identificar el valor del big data no pasa solo por analizarlo (que es ya una ventaja en sí misma). Se trata de todo un proceso de descubrimiento que requiere que los analistas, usuarios empresariales y ejecutivos se planteen las preguntas correctas, identifiquen patrones, tomen decisiones informadas y predigan comportamientos.</p>\n<h3>La historia de big data</h3>\n<p>Si bien el concepto &ldquo;big data&rdquo; en sí mismo es relativamente nuevo, los orígenes de los grandes conjuntos de datos se remontan a las décadas de 1960 y 1970, donde se sitúan los albores de este universo con los primeros centros de datos y el desarrollo de las bases de datos relacionales.</p>\n<p>Alrededor de 2005, la gente empezó a darse cuenta de la cantidad de datos que generaban los usuarios a través de Facebook, YouTube y otros servicios online. Ese mismo año, se desarrollaría Hadoop, un marco de código abierto creado específicamente para almacenar y analizar grandes conjuntos de datos. En esta época, también empezaría a adquirir popularidad NoSQL.</p>\n<p>El desarrollo de Framewoks de código abierto tales como Hadoop (y, más recientemente, Spark) sería esencial para el crecimiento del big data, pues estos hacían que el big data resultase más fácil de usar y más barato de almacenar. En los años siguientes, el volumen de big data se ha disparado. Los usuarios continúan generando enormes cantidades de datos, pero ahora los humanos no son los únicos que lo hacen.</p>\n<p>Con la llegada del Internet de las cosas (IoT), hay un mayor número de objetos y dispositivos conectados a Internet que generan datos sobre patrones de uso de los clientes y rendimiento de los productos. El surgimiento del aprendizaje automático ha producido aún más datos.</p>\n<p>Aunque el big data ha llegado lejos, su utilidad no ha hecho más que empezar. El Cloud Computing ha ampliado aún más las posibilidades del big data. La nube ofrece una escalabilidad realmente elástica, donde los desarrolladores pueden simplemente agilizar clústeres ad hoc para probar un subconjunto de datos.</p>\n<h3>Ventajas de big data y de la analítica de datos</h3>\n<ul>\n<li>El big data le permite obtener respuestas más completas, ya que dispone de mayor cantidad de información.</li>\n<li>La disponibilidad de respuestas más completas significa una mayor fiabilidad de los datos, lo que implica un enfoque completamente distinto a la hora de abordar problemas.</li>\n</ul>\n<h3>Casos de uso de big data</h3>\n<p>El big data puede ayudarle a abordar una serie de actividades empresariales, desde la experiencia de cliente hasta la analítica. A continuación, recopilamos algunas de ellas</p>\n<h4>Desarrollo de productos</h4>\n<p>Empresas como Netflix y Procter &amp; Gamble usan big data para prever la demanda de los clientes. Construyen modelos predictivos para nuevos productos y servicios clasificando atributos clave de productos anteriores y actuales, y modelando la relación entre dichos atributos y el éxito comercial de las ofertas. Además, P&amp;G utiliza los datos y la analítica de grupos de interés, redes sociales, mercados de prueba y avances de salida en tiendas para planificar, producir y lanzar nuevos productos.</p>\n<h4>Mantenimiento predictivo</h4>\n<p>Los factores capaces de predecir fallos mecánicos pueden estar profundamente ocultos entre datos estructurados (año del equipo, marca o modelo de una máquina) o entre datos no estructurados que cubren millones de entradas de registros, datos de sensores, mensajes de error y temperaturas de motor. Al analizar estos indicadores de problemas potenciales antes de que estos se produzcan, las organizaciones pueden implantar el mantenimiento de una forma más rentable y optimizar el tiempo de servicio de componentes y equipos.</p>\n<h4>Experiencia del cliente</h4>\n<p>La carrera para conseguir clientes ha comenzado. Disponer de una vista clara de la experiencia del cliente es más posible que nunca. El big data le permite recopilar datos de redes sociales, visitas a páginas web, registros de llamadas y otras fuentes de datos para mejorar la experiencia de interacción, así como maximizar el valor ofrecido. Empiece a formular ofertas personalizadas, reducir las tasas de abandono de los clientes y gestionar las incidencias de manera proactiva.</p>\n<h4>Fraude y conformidad</h4>\n<p>En lo que a seguridad se refiere, no se enfrenta a simples piratas informáticos deshonestos, sino a equipos completos de expertos. Los contextos de seguridad y requisitos de conformidad están en constante evolución. El big data le ayuda a identificar patrones en los datos que pueden ser indicativos de fraude, al tiempo que concentra grandes volúmenes de información para agilizar la generación de informes normativos.</p>\n<h4>Aprendizaje automático (Machine Learning)</h4>\n<p>El aprendizaje automático es actualmente un tema de gran actualidad. Los datos —concretamente big data— son uno de los motivos de que así sea. Ahora, en lugar de programarse, las máquinas pueden aprender. Esto es posible gracias a la disponibilidad de big data para crear modelos de aprendizaje automático.</p>\n<h4>Eficiencia operativa</h4>\n<p>Puede que la eficiencia operativa no sea el aspecto más destacado en los titulares, pero es el área en que big data tiene un mayor impacto. El big data le permite analizar y evaluar la producción, la opinión de los clientes, las devoluciones y otros factores para reducir las situaciones de falta de stock y anticipar la demanda futura. El big data también puede utilizarse para mejorar la toma de decisiones en función de la demanda de mercado en cada momento.</p>\n<h4>Impulso de la innovación</h4>\n<p>El big data puede ayudarle a innovar mediante el estudio de las interdependencias entre seres humanos, instituciones, entidades y procesos, y, posteriormente, mediante la determinación de nuevas formas de usar dicha información. Utilice las perspectivas que le ofrecen los datos para mejorar sus decisiones financieras y consideraciones de planificación. Estudie las tendencias y lo que desean los clientes para ofrecer nuevos productos y servicios. Implante políticas de precios dinámicas. Las posibilidades son infinitas.</p>\n<h3>Desafíos de big data</h3>\n<p>Si bien es cierto que el big data promete mucho, también se enfrenta a desafíos.</p>\n<p>En primer lugar, el big data se caracteriza por su gran tamaño. Aunque se han desarrollado nuevas tecnologías para el almacenamiento de datos, el volumen de datos duplica su tamaño cada dos años aproximadamente. Las organizaciones continúan esforzándose por mantener el ritmo de crecimiento de sus datos y por encontrar formas de almacenarlos eficazmente.</p>\n<p>Pero no basta con almacenar los datos. Para ser de algún valor, los datos deben poder utilizarse, y esto depende de su conservación. Disponer de datos limpios —es decir, datos relevantes para el cliente y organizados de tal modo que permitan un análisis significativo— requiere una gran cantidad de trabajo. Los científicos de datos dedican entre un 50 y un 80 por ciento de su tiempo a seleccionar y preparar los datos antes de que estos puedan utilizarse.</p>\n<p>Por último, la tecnología de big data cambia a un ritmo rápido. Hace unos años, Apache Hadoop era la tecnología más conocida utilizada para gestionar big data. Más tarde, en 2014, entraría en juego Apache Spark. Hoy en día, el enfoque óptimo parece ser una combinación de ambos frameworks. Mantenerse al día en cuanto a tecnología de big data supone un desafío constante.</p>\n<h3>¿Cómo funciona big data?</h3>\n<p>El big data le aporta nuevas perspectivas que abren paso a nuevas oportunidades y modelos de negocio. Iniciarse en ello requiere de tres acciones clave:</p>\n<h4>Integrar</h4>\n<p>El big data concentra datos de numerosas fuentes y aplicaciones distintas. Los mecanismos de integración de datos convencionales, tales como ETL (extract, transform, load [extraer, transformar, cargar]), generalmente no están a la altura en dicha tarea. Analizar conjuntos de big data de uno o más terabytes, o incluso petabytes, de tamaño requiere de nuevas estrategias y tecnologías.</p>\n<p>Durante la integración, es necesario incorporar los datos, procesarlos y asegurarse de que estén formateados y disponibles de tal forma que los analistas empresariales puedan empezar a utilizarlos.</p>\n<h4>Gestionar</h4>\n<p>El big data requiere almacenamiento. Su solución de almacenamiento puede residir en la nube, on premise o ambas. Puede almacenar sus datos de cualquier forma que desee e incorporar los requisitos de procesamiento de su preferencia y los motores de procesamiento necesarios a dichos conjuntos de datos on-demand. Muchas personas eligen su solución de almacenamiento en función de dónde residan sus datos en cada momento. La nube está aumentando progresivamente su popularidad porque es compatible con sus requisitos tecnológicos actuales y porque le permite incorporar recursos a medida que los necesita.</p>\n<h4>Analizar</h4>\n<p>La inversión en big data se rentabiliza en cuanto se analizan y utilizan los datos. Adquiera una nueva claridad con un análisis visual de sus diversos conjuntos de datos. Continúe explorando los datos para realizar nuevos descubrimientos. Comparta sus hallazgos con otras personas. Construya modelos de datos con aprendizaje automático e inteligencia artificial. Ponga sus datos a trabajar.</p>\n<h3>Mejores prácticas de big data</h3>\n<p>Para ayudarle en su transición a big data, hemos recopilado una serie de mejores prácticas que debe tener en cuenta. A continuación, detallamos nuestras pautas para crear con éxito una base de big data.</p>\n<h4>Alinear big data con objetivos empresariales específicos</h4>\n<p>La disponibilidad de conjuntos de datos más amplios le permite realizar nuevos hallazgos. A tal efecto, es importante basar las nuevas inversiones en habilidades, organización o infraestructura con un marcado contexto empresarial para garantizar la constancia en la financiación e inversión en proyectos. Para determinar si se encuentra en el camino correcto, pregúntese en qué medida el big data respalda y habilita sus principales prioridades empresariales y de TI. Algunos ejemplos incluyen entender cómo filtrar los registros web para comprender el comportamiento del comercio electrónico, extraer el sentimiento de las redes sociales y de las interacciones de atención al cliente, así como entender los métodos de correlación estadística y su relevancia para los datos de clientes, productos, fabricación e ingeniería.</p>\n<h4>Facilite la escasez de habilidades con estándares y administración</h4>\n<p>Uno de los mayores obstáculos del big data es la escasez de habilidades. Puede mitigar el riesgo asegurándose de incorporar a su programa de administración de TI tecnologías, consideraciones y decisiones relativas a big data. Normalizar su enfoque le permitirá gestionar los costes y aprovechar los recursos. Las organizaciones que implanten soluciones y estrategias de big data deben evaluar sus necesidades de habilidades de forma temprana y frecuente, e identificar de manera proactiva las posibles carencias de habilidades. Esto puede lograrse mediante la impartición de formación o la formación cruzada entre recursos existentes, la contratación de nuevos recursos y el uso de empresas de consultoría.</p>\n<h4>Optimizar la transferencia de conocimientos con un centro de excelencia</h4>\n<p>Utilice un enfoque basado en un centro de excelencia para compartir conocimientos, supervisar el control y gestionar las comunicaciones de proyectos. Tanto si el big data es una inversión nueva o en expansión, los costes directos e indirectos pueden distribuirse en toda la empresa. Utilizar este enfoque puede contribuir a incrementar las capacidades de big data y la madurez del conjunto de la arquitectura de información de una forma más sistemática y estructurada.</p>\n<h4>La principal ventaja reside en alinear los datos estructurados y no estructurados</h4>\n<p>Analizar el big data de forma aislada sin duda aporta valor. Sin embargo, puede obtener una perspectiva empresarial aún más valiosa relacionando e integrando el big data de baja densidad con los datos estructurados que ya usa actualmente.</p>\n<p>Tanto si está recopilando big data de clientes, de productos, de equipos o ambientales, el objetivo es añadir puntos de datos más relevantes a sus resúmenes maestros y analíticos, lo que le permitirá obtener mejores conclusiones. Por ejemplo, existe una diferencia en distinguir la percepción de todos los clientes de la de solo sus mejores clientes. Por eso, muchos consideran que big data constituye una extensión integral de sus capacidades existentes de inteligencia empresarial, de su plataforma de almacenamiento de datos y de su arquitectura de información.</p>\n<p>Tenga en cuenta que los modelos y procesos analíticos de big data pueden ser tanto humanos como automáticos. Las capacidades de análisis de big data incluyen estadísticas, análisis especiales, semántica, detección interactiva y visualización. Mediante el uso de modelos analíticos, puede relacionar distintos tipos y fuentes de datos para realizar asociaciones y hallazgos significativos.</p>\n<h4>Planificar el laboratorio de hallazgos en pro del rendimiento</h4>\n<p>El concepto &ldquo;hallazgo&rdquo; implica que los datos no siempre se obtienen directamente. En ocasiones, ni siquiera sabemos qué estamos buscando. Eso es de esperar. La dirección y los equipos de TI deben respaldar esta “falta de dirección” o “falta de claridad en los requisitos.”</p>\n<p>Al mismo tiempo, es importante que analistas y científicos de datos colaboren estrechamente con la empresa para entender las principales necesidades y carencias de conocimientos de la empresa. Para incorporar el estudio interactivo de los datos y la experimentación de algoritmos estadísticos, necesita contar con áreas de trabajo de alto rendimiento. Asegúrese de que los entornos de pruebas (sandbox) tienen la potencia necesaria y están correctamente gobernados.</p>\n<h4>Alineación con el modelo operativo en la nube</h4>\n<p>Los usuarios y procesos de big data requieren acceso a una amplia variedad de recursos de experimentación reiterativa y ejecución de tareas de producción. Una solución de big data incluye todos los ámbitos de los datos, incluidas transacciones, datos principales, datos de referencia y datos resumidos. Los entornos de pruebas (sandboxes) analíticos deben crearse on-demand. La gestión de recursos es fundamental para garantizar el control de todo el flujo de datos, incluido el procesamiento previo y posterior, la integración, el resumen dentro de la base de datos y la creación de modelos analíticos. Disponer de una estrategia bien definida de aprovisionamiento y seguridad en la nube pública y privada es fundamental para respaldar estos requisitos cambiantes.</p>\n<h3>¿Qué ha dado lugar a la prominencia de big data?</h3>\n<h4>escenarios</h4>\n<p>Escenarios donde se producen grandes volúmenes de datos, el clásico ejemplo es internet (redes sociales, blogs, imágenes, videos, etc), hay otros escenarios como la cadena de suministro, que se encarga de todo el inventario de almacenes a niveles enormes, incluso las torres de celulares producen grandes cantidades de información, incluso antes, los códigos upc, que son los códigos de barra de productos en almacenes también han producido grandes cantidades de datos.</p>\n<h4>¿Qué es lo que ha permitido la llegada big data?</h4>\n<p>Big data es compatible con hardware básico (servidores baratos, discos baratos), reducción en costos de almacenamiento, muchas de las tecnologías big data se basa en software de código abierto, la economía web (migración de todo tipo de negocios ha generado una necesidad de generar y consumir datos)</p>\n<h3>¿que se puede hacer con big data?</h3>\n<p>Análisis de clicks, patrones de compra\n<br  />Análisis de sentimientos\n<br  />Detección de fraudes\n<br  />Estrategias de inversión (ML)\n<br  />Investigaciones sobre salud\n<br  />Predicción y prevención de fallas de equipos</p>\n<h3>Definiendo más específicamente por aspectos</h3>\n<p>*Tamaño: No hay un estándar que diga que cantidad de datos se necesita para que sea considerada big data, pero si míralos las tecnologías que no pertenecen a big data se podría decir que a partir del rango de cientos de terabytes, considerado el umbral, se comienza a requerir tecnologías big data porque las tradicionales ya no funcionan bien, pedabyte es 1024 terabytes.</p>\n<p>3s V's:</p>\n<ul>\n<li>Volumen: Se refiere a la cantidad de datos.</li>\n<li>Velocidad: Que tan rápido esos datos están llegando y que tan rápido se tiene que procesar</li>\n<li>Variedad: se refiere a la estructura de los datos, la mayoria de datos son datos no relacionales (organizados en filas o columnas)</li>\n</ul>\n<p><strong>Big data es demasiado grande para bases de datos OLTP (OnLine Transaction Processing)</strong></p>\n<p>Usa procesamiento distribuido (o en paralelo), porque la idea es que si tienen un recurso de big data lo que se quiere haces es dividir los datos en partes más pequeñas y que sean procesados a través de un cluster</p>\n<p><a href=\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\" title=\"Big Data Landscape 2018\"><img src=\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\" alt=\"\" /></a></p>\n"}]},"apps":[],"jobName":"paragraph_1530036527064_1726470972","id":"20180626-180847_967833253","dateCreated":"2018-06-26T18:08:47+0000","dateStarted":"2018-06-27T21:48:36+0000","dateFinished":"2018-06-27T21:48:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:581"},{"text":"","user":"anonymous","dateUpdated":"2018-06-27T21:48:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":true,"language":"markdown"},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1530046902360_71313947","id":"20180626-210142_1608139983","dateCreated":"2018-06-26T21:01:42+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:582"}],"name":"Introducción","id":"2DHGTQ9NC","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2CKAY1A8Y:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}