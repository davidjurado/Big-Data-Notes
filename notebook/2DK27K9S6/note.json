{
  "paragraphs": [
    {
      "text": "%md\n\n# El ecosistema de Big Data \n\nBig Data no es solo un problema de base de datos o una herramienta en particular, es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.\n\nEl ecosistema de Big Data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del Big Data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas de la tecnología. Resulta sumamente difícil describir todas las tecnologías que componen el ecosistema de Big Data, es por esto que dichas tecnologías han sido divididas en diferentes categorías y estas a su vez se han llegado a dividir en áreas mas especificas. A continuación se definen algunas de las categorías y componentes más importantes que abordan los diferentes aspectos del ecosistema de Big Data:\n\n---\n\n#### Tipos de datos\n\nLas diferentes etapas de la transformación de Big Data requieren y utilizan diferentes estructuras de datos, modelos y formatos.\n\n\u003cbr\u003e\n\n\u003cp\u003e\n\u003cimg align\u003d\"left\" width\u003d\"700\" height\u003d\"350\" src\u003d\"https://dtflaneur.files.wordpress.com/2013/02/svuns.png?w\u003d700\"\u003e\n\u003c/p\u003e\n\n\n* **Datos estructurados**: Los datos estructurados se refieren a todos los datos que se pueden almacenar una base de datos relacional, en tablas con filas y columnas. Tienen una clave relacional y se pueden mapear fácilmente en campos prediseñados. La información estructurada es relativamente simple de ingresar, almacenar, consultar y analizar, pero debe estar estrictamente definida en términos de nombre y tipo de campo.\n\n* **Datos no estructurados**: Los datos no estructurados pueden tener su propia estructura interna, pero no se ajustan perfectamente a una hoja de cálculo o base de datos. El desafío fundamental de las fuentes de datos no estructurados es que son difíciles de descifrar, comprender y preparar para el uso analítico.\n\n* **Datos semiestructurados**: Los datos semiestructurados son información que no reside en una base de datos relacional pero que tiene algunas propiedades organizacionales que hacen que sea más fácil de analizar. Por ejemplo los archivos CSV, XML y JSON son documentos semiestructurados y las bases de datos NoSQL se consideran semiestructuradas.\n\n---\n#### Motores de ejecución\n\n\u003cbr\u003e\n\n\u003cimg height\u003d\"100\" width\u003d\"300\" src\u003d\"https://hadoop.apache.org/images/hadoop-logo.jpg\"\u003e\n\n* **Apache Hadoop** : Es un framework de código abierto de Apache escrito en java que permite el procesamiento distribuido de grandes conjuntos de datos en grupos de computadores utilizando modelos de programación simples. Una aplicación que trabaja en Hadoop funciona en un entorno que proporciona almacenamiento distribuido y computación entre clusters de computadoras. Hadoop está diseñado para escalar desde un único servidor a miles de máquinas, cada una de las cuales ofrece cómputo y almacenamiento local. Los componentes principales de Hadoop son:\n\n    * **HDFS** : Es un sistema de archivos distribuidos y tolerante a fallas, diseñado para convertir un grupo de servidores estándar en un grupo de almacenamiento de escalamiento masivo. Desarrollado específicamente para cargas de trabajo de procesamiento de datos a gran escala donde la escalabilidad, la flexibilidad y el rendimiento son críticos.\n    \n    * **MapReduce** : MapReduce es el corazón de Apache Hadoop. Es este paradigma de programación que permite una escalabilidad masiva en cientos o miles de servidores en un clúster de Hadoop, permite escribir fácilmente aplicaciones que procesan grandes cantidades de datos en paralelo en grandes clusters (miles de nodos) de hardware básico de una manera confiable y tolerante a fallas.\n    \n    * **YARN** : Es un framework para la programación de trabajos y la administración de recursos del clúster. Proporciona administración de recursos de código abierto para Hadoop, por lo que puede ir más allá del procesamiento por lotes y abrir sus datos a un conjunto diverso de cargas de trabajo, que incluyen SQL interactivo, modelado avanzado y transmisión en tiempo real.\n    \n\u003cimg  height\u003d\"100\" src\u003d\"https://tez.apache.org/images/ApacheTezLogo_lowres.png\"\u003e\n\n* **Apache Tez**: Apache Tez es un framework extensible para la construcción de lotes de alto rendimiento y aplicaciones interactivas de procesamiento de datos, coordinado por YARN en Apache Hadoop. Tez mejora el paradigma MapReduce al mejorar drásticamente su velocidad, al tiempo que mantiene la capacidad de MapReduce para escalar a petabytes de datos.\n\n\u003cimg  height\u003d\"100\" src\u003d\"https://spark.apache.org/images/spark-logo-trademark.png\"\u003e\n\n* **Apache Spark**: Es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos. Con Spark funcionando en Apache Hadoop YARN, los desarrolladores de todo el mundo ahora pueden crear aplicaciones para explotar el poder de Spark, obtener ideas y enriquecer sus cargas de trabajo de ciencia de datos dentro de un solo conjunto de datos compartido en Hadoop.\n\n\u003cimg  height\u003d\"100\" src\u003d\"https://flink.apache.org/img/flink-header-logo.svg\"\u003e\n\n* **Apache Flink**: Apache Flink (en alemán significa \"rápido\") es un framework de Big Data para el procesamiento de datos por lotes y en streaming. Permite a los desarrolladores construir pipelines de procesamiento de datos complejas y ejecutarlas en un entorno distribuido. Proporciona un soporte de primera clase para el procesamiento en streaming e implementa el procesamiento por lotes como un caso especial.\n\n---\n\n#### Bases de datos\n\n\u003cbr\u003e\n\n\u003cp align\u003d\"center\"\u003e\n\u003cimg  src\u003d\"https://blog.couchbase.com/wp-content/uploads/2017/04/nosql-vs-sql-overview-1.png\"\u003e\n\u003c/p\u003e\n\n* **Bases de datos realacionales**: Bases de datos operacionales para aplicaciones OLTP que requieren altas cargas de transacciones y concurrencia del usuario. Puede \"ampliarse\" a volúmenes de datos, pero no tiene la capacidad de \"escalar horizontalmente\" para el procesamiento de datos de gran tamaño. Poseen un esquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL. Algunas de las más populares son SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.\n\n* **Base de datos analíticas**: Esquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados. Los esquemas rígidos con consultas SQL orientadas a lotes no están diseñados para aplicaciones de streaming. Algunas de las más populares son Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica.\n\n* **Bases de datos NoSQL**: Bueno para aplicaciones web, código de aplicación web sin escritura, depuración y mantenimiento. Escale el escalado horizontal con datos automáticos para admitir a millones de usuarios de aplicaciones web. Compromiso de coherencia (transacciones ACID) a favor de la escala y el tiempo de actividad. El diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda. Algunas de las más populares son: MongoDB, HBase, Cassandra, MarkLogic, Couchbase.\n\n* **Bases de datos NewSQL**: Corresponde a un nuevo (relativamente) tipo de base de datos que se considera un nuevo paradigma de base de datos RDBMS, en el que se aplican las lecciones aprendidas de las bases de datos NoSQL en el mundo SQL. Están pensadas principalmente para aplicaciones que requieren gestionar gran cantidad de registros, pero con la consistencia que ofrecen las RDBMS y mediante lenguaje SQL. Con respecto a este tipo de bases de datos, hay dos variantes: las que se han creado desde el principio con este concepto (VoltDB, MemSQL, etc.) y las que se han adaptado a este requisito, como es el caso de MySQL Cluster. Algunas de las más populares son Altibase, c-treeACE, CockroachDB, NuoDB, VoltDB.\n\n---\n\n### Streaming\n\n\u003cbr\u003e\n\n\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"http://storm.apache.org/images/logo.png\"\u003e\n\n* **Apache Storm**: Apache Storm es un sistema de computación distribuido, tolerante a fallas y de código abierto. Storm procesa flujos de datos en tiempo real con Hadoop. Las soluciones de Storm también pueden proporcionar un procesamiento de datos garantizado, con la capacidad de reproducir datos que no se procesaron correctamente la primera vez.\n\n\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"https://nifi.apache.org/assets/images/apache-nifi-logo.svg\"\u003e\n\n* **Apache Nifi**: Apache NiFi es una plataforma integrada de logística de datos para automatizar el movimiento de datos entre sistemas dispares. Proporciona control en tiempo real que facilita la gestión del movimiento de datos entre cualquier fuente y cualquier destino.\n\n\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"http://kafka.apache.org/images/logo.png\"\u003e\n\n* **Apache Kafka**: Apache Kafka es una plataforma de transmisión distribuida capaz de manejar billones de eventos al día. Inicialmente concebido como una cola de mensajes, Kafka se basa en una abstracción de un registro de compromiso distribuido.\n\n### Machine Learning\n\nY hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.\n\n\n(2) Administración Big Data\n\nLas tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.\n\n* Ciclo de vida de Big Data (Gestión)\n* Transformación y puesta en escena\n* Origen, Limpieza, Archivado\n\n(3) Analítica Big Data y herramientas\n\nAdemás de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:\n\nServicios de cluster\n\nServicios y herramientas relacionados con Hadoop\n\nHerramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)\n\nBases de datos / Servidores SQL, NoSQL\n\nBases de datos MPP (Massively Parallel Processing)\n\nActualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.\n\n* Aplicaciones Big Data\n* Objetivo de uso, presentación, visualización\n\n(4) Infraestructura Big Data\n\nLos servicios y componentes generales de la infraestructura de Big Data incluyen:\n\nHerramientas administración de Big Data\n\nRegistros, indexación/búsqueda, semántica, espacios de nombres\n\nInfraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)\n\nEntorno colaborativo (gestión de grupos)\n\n* Almacenamiento, red de procesamiento (HPC)\n* Red de sensores, dispositivos accionables\n* Soporte operacional Big Data\n\n(5) Seguridad de Big Data\n\nEsta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:\n\nCiclo de vida de seguridad\n\nControl de acceso de grano fino\n\nControl de acceso forzado de encriptación\n\nEntorno de confianza\n\nFADI para la cooperación y la integración de servicios\n\n* Seguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables\n\n(9) HDFS MapReduce\n\nSoluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights\n\nSistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos\n\n(10) SQL en Hadoop\n\nHerramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL\n\nSQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)\n\n(11) Búsqueda distribuida\n\nejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch\n\nElastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.\n\n(12) Transmisión de mensajes\n\nKafka, JMS, AMQ\n\nTransmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes\n\n(13) Procesamiento de flujo de eventos\n\nApache Storm\n\nStorm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo \"al menos una vez semántica\" a favor de la velocidad.\n\n(14) procesamiento de eventos complejos\n\nSpark, Flink\n\nProcesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.\n\n(15) \n\n* BI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de Big Data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.\n\n(16)\n* Distribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los \"tres grandes\" (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.\n\n\n(18)\n* SQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea \"más fácil\" de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de Big Data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.\n\n(19)\n* Para codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de Big Data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.\n\n\u003cp align\u003d\"center\"\u003e\n  \u003cimg src\u003d\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\"\u003e\n\u003c/p\u003e\n\n### Mejores prácticas para avanzar en el ecosistema de Big Data\n\nSí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de Big Data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.\n\n## Big Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso\n\nNo te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de Big Data citado por los encuestados fue \"determinar cómo obtener valor del Big Data\" (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.\n\n## Big Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización\n\nComo se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.\n\n## Big Data Ecosystem Best Practice # 3: Piensa preparado para el futuro\n\nYa lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es \"a prueba de futuro\" o \"preparada para el futuro\" a través de una arquitectura modular y \"conectable\". Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.\n\n\n\n[Datameer](https://www.datameer.com/blog/big-data-ecosystem/ \"Datameer\")\n\n\nEl Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.\n\nDe acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:\n\n* Consistencia: cada cliente siempre tiene la misma visión de los datos.\n* Disponibilidad: todos los clientes siempre pueden leer y escribir.\n* Tolerancia de partición: el sistema funciona bien en las particiones de red física.\n\n\n[mattturck 2018](http://mattturck.com/bigdata2018/ \"mattturck 2018\")\n[mattturck 2017](http://mattturck.com/bigdata2017/ \"mattturck 2017\")\n\n\notros recursos a revisar:\n\n[1](https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf)\n[2](https://www.nature.com/articles/527S16a)\n[3](http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf)\n[4](https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf)\n[5!](https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#)\n[6](https://interset.com/2018/01/23/big-data-tech-explained-part-1/)\n[7](https://interset.com/2018/01/30/big-data-tech-part-2/)",
      "user": "anonymous",
      "dateUpdated": "Jul 6, 2018 11:48:23 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "editOnDblClick": true,
          "language": "markdown"
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eEl ecosistema de Big Data\u003c/h1\u003e\n\u003cp\u003eBig Data no es solo un problema de base de datos o una herramienta en particular, es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.\u003c/p\u003e\n\u003cp\u003eEl ecosistema de Big Data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del Big Data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas de la tecnología. Resulta sumamente difícil describir todas las tecnologías que componen el ecosistema de Big Data, es por esto que dichas tecnologías han sido divididas en diferentes categorías y estas a su vez se han llegado a dividir en áreas mas especificas. A continuación se definen algunas de las categorías y componentes más importantes que abordan los diferentes aspectos del ecosistema de Big Data:\u003c/p\u003e\n\u003chr /\u003e\n\u003ch4\u003eTipos de datos\u003c/h4\u003e\n\u003cp\u003eLas diferentes etapas de la transformación de Big Data requieren y utilizan diferentes estructuras de datos, modelos y formatos.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003e\n\u003cimg align\u003d\"left\" width\u003d\"700\" height\u003d\"350\" src\u003d\"https://dtflaneur.files.wordpress.com/2013/02/svuns.png?w\u003d700\"\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDatos estructurados\u003c/strong\u003e: Los datos estructurados se refieren a todos los datos que se pueden almacenar una base de datos relacional, en tablas con filas y columnas. Tienen una clave relacional y se pueden mapear fácilmente en campos prediseñados. La información estructurada es relativamente simple de ingresar, almacenar, consultar y analizar, pero debe estar estrictamente definida en términos de nombre y tipo de campo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDatos no estructurados\u003c/strong\u003e: Los datos no estructurados pueden tener su propia estructura interna, pero no se ajustan perfectamente a una hoja de cálculo o base de datos. El desafío fundamental de las fuentes de datos no estructurados es que son difíciles de descifrar, comprender y preparar para el uso analítico.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDatos semiestructurados\u003c/strong\u003e: Los datos semiestructurados son información que no reside en una base de datos relacional pero que tiene algunas propiedades organizacionales que hacen que sea más fácil de analizar. Por ejemplo los archivos CSV, XML y JSON son documentos semiestructurados y las bases de datos NoSQL se consideran semiestructuradas.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr /\u003e\n\u003ch4\u003eMotores de ejecución\u003c/h4\u003e\n\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg height\u003d\"100\" width\u003d\"300\" src\u003d\"https: //hadoop.apache.org/images/hadoop-logo.jpg\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eApache Hadoop\u003c/strong\u003e : Es un framework de código abierto de Apache escrito en java que permite el procesamiento distribuido de grandes conjuntos de datos en grupos de computadores utilizando modelos de programación simples. Una aplicación que trabaja en Hadoop funciona en un entorno que proporciona almacenamiento distribuido y computación entre clusters de computadoras. Hadoop está diseñado para escalar desde un único servidor a miles de máquinas, cada una de las cuales ofrece cómputo y almacenamiento local. Los componentes principales de Hadoop son:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eHDFS\u003c/strong\u003e : Es un sistema de archivos distribuidos y tolerante a fallas, diseñado para convertir un grupo de servidores estándar en un grupo de almacenamiento de escalamiento masivo. Desarrollado específicamente para cargas de trabajo de procesamiento de datos a gran escala donde la escalabilidad, la flexibilidad y el rendimiento son críticos.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMapReduce\u003c/strong\u003e : MapReduce es el corazón de Apache Hadoop. Es este paradigma de programación que permite una escalabilidad masiva en cientos o miles de servidores en un clúster de Hadoop, permite escribir fácilmente aplicaciones que procesan grandes cantidades de datos en paralelo en grandes clusters (miles de nodos) de hardware básico de una manera confiable y tolerante a fallas.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eYARN\u003c/strong\u003e : Es un framework para la programación de trabajos y la administración de recursos del clúster. Proporciona administración de recursos de código abierto para Hadoop, por lo que puede ir más allá del procesamiento por lotes y abrir sus datos a un conjunto diverso de cargas de trabajo, que incluyen SQL interactivo, modelado avanzado y transmisión en tiempo real.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" src\u003d\"https: //tez.apache.org/images/ApacheTezLogo_lowres.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Tez\u003c/strong\u003e: Apache Tez es un framework extensible para la construcción de lotes de alto rendimiento y aplicaciones interactivas de procesamiento de datos, coordinado por YARN en Apache Hadoop. Tez mejora el paradigma MapReduce al mejorar drásticamente su velocidad, al tiempo que mantiene la capacidad de MapReduce para escalar a petabytes de datos.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" src\u003d\"https: //spark.apache.org/images/spark-logo-trademark.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Spark\u003c/strong\u003e: Es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos. Con Spark funcionando en Apache Hadoop YARN, los desarrolladores de todo el mundo ahora pueden crear aplicaciones para explotar el poder de Spark, obtener ideas y enriquecer sus cargas de trabajo de ciencia de datos dentro de un solo conjunto de datos compartido en Hadoop.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" src\u003d\"https: //flink.apache.org/img/flink-header-logo.svg\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Flink\u003c/strong\u003e: Apache Flink (en alemán significa \u0026ldquo;rápido\u0026rdquo;) es un framework de Big Data para el procesamiento de datos por lotes y en streaming. Permite a los desarrolladores construir pipelines de procesamiento de datos complejas y ejecutarlas en un entorno distribuido. Proporciona un soporte de primera clase para el procesamiento en streaming e implementa el procesamiento por lotes como un caso especial.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr /\u003e\n\u003ch4\u003eBases de datos\u003c/h4\u003e\n\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\n\u003cp align\u003d\"center\"\u003e\n\u003cimg  src\u003d\"https://blog.couchbase.com/wp-content/uploads/2017/04/nosql-vs-sql-overview-1.png\"\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBases de datos realacionales\u003c/strong\u003e: Bases de datos operacionales para aplicaciones OLTP que requieren altas cargas de transacciones y concurrencia del usuario. Puede \u0026ldquo;ampliarse\u0026rdquo; a volúmenes de datos, pero no tiene la capacidad de \u0026ldquo;escalar horizontalmente\u0026rdquo; para el procesamiento de datos de gran tamaño. Poseen un esquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL. Algunas de las más populares son SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBase de datos analíticas\u003c/strong\u003e: Esquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados. Los esquemas rígidos con consultas SQL orientadas a lotes no están diseñados para aplicaciones de streaming. Algunas de las más populares son Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBases de datos NoSQL\u003c/strong\u003e: Bueno para aplicaciones web, código de aplicación web sin escritura, depuración y mantenimiento. Escale el escalado horizontal con datos automáticos para admitir a millones de usuarios de aplicaciones web. Compromiso de coherencia (transacciones ACID) a favor de la escala y el tiempo de actividad. El diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda. Algunas de las más populares son: MongoDB, HBase, Cassandra, MarkLogic, Couchbase.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBases de datos NewSQL\u003c/strong\u003e: Corresponde a un nuevo (relativamente) tipo de base de datos que se considera un nuevo paradigma de base de datos RDBMS, en el que se aplican las lecciones aprendidas de las bases de datos NoSQL en el mundo SQL. Están pensadas principalmente para aplicaciones que requieren gestionar gran cantidad de registros, pero con la consistencia que ofrecen las RDBMS y mediante lenguaje SQL. Con respecto a este tipo de bases de datos, hay dos variantes: las que se han creado desde el principio con este concepto (VoltDB, MemSQL, etc.) y las que se han adaptado a este requisito, como es el caso de MySQL Cluster. Algunas de las más populares son Altibase, c-treeACE, CockroachDB, NuoDB, VoltDB.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr /\u003e\n\u003ch3\u003eStreaming\u003c/h3\u003e\n\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"http: //storm.apache.org/images/logo.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Storm\u003c/strong\u003e: Apache Storm es un sistema de computación distribuido, tolerante a fallas y de código abierto. Storm procesa flujos de datos en tiempo real con Hadoop. Las soluciones de Storm también pueden proporcionar un procesamiento de datos garantizado, con la capacidad de reproducir datos que no se procesaron correctamente la primera vez.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"https: //nifi.apache.org/assets/images/apache-nifi-logo.svg\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Nifi\u003c/strong\u003e: Apache NiFi es una plataforma integrada de logística de datos para automatizar el movimiento de datos entre sistemas dispares. Proporciona control en tiempo real que facilita la gestión del movimiento de datos entre cualquier fuente y cualquier destino.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg  height\u003d\"100\" width\u003d\"300\" src\u003d\"http: //kafka.apache.org/images/logo.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eApache Kafka\u003c/strong\u003e: Apache Kafka es una plataforma de transmisión distribuida capaz de manejar billones de eventos al día. Inicialmente concebido como una cola de mensajes, Kafka se basa en una abstracción de un registro de compromiso distribuido.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMachine Learning\u003c/h3\u003e\n\u003cp\u003eY hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.\u003c/p\u003e\n\u003cp\u003e(2) Administración Big Data\u003c/p\u003e\n\u003cp\u003eLas tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCiclo de vida de Big Data (Gestión)\u003c/li\u003e\n\u003cli\u003eTransformación y puesta en escena\u003c/li\u003e\n\u003cli\u003eOrigen, Limpieza, Archivado\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(3) Analítica Big Data y herramientas\u003c/p\u003e\n\u003cp\u003eAdemás de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:\u003c/p\u003e\n\u003cp\u003eServicios de cluster\u003c/p\u003e\n\u003cp\u003eServicios y herramientas relacionados con Hadoop\u003c/p\u003e\n\u003cp\u003eHerramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)\u003c/p\u003e\n\u003cp\u003eBases de datos / Servidores SQL, NoSQL\u003c/p\u003e\n\u003cp\u003eBases de datos MPP (Massively Parallel Processing)\u003c/p\u003e\n\u003cp\u003eActualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAplicaciones Big Data\u003c/li\u003e\n\u003cli\u003eObjetivo de uso, presentación, visualización\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(4) Infraestructura Big Data\u003c/p\u003e\n\u003cp\u003eLos servicios y componentes generales de la infraestructura de Big Data incluyen:\u003c/p\u003e\n\u003cp\u003eHerramientas administración de Big Data\u003c/p\u003e\n\u003cp\u003eRegistros, indexación/búsqueda, semántica, espacios de nombres\u003c/p\u003e\n\u003cp\u003eInfraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)\u003c/p\u003e\n\u003cp\u003eEntorno colaborativo (gestión de grupos)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAlmacenamiento, red de procesamiento (HPC)\u003c/li\u003e\n\u003cli\u003eRed de sensores, dispositivos accionables\u003c/li\u003e\n\u003cli\u003eSoporte operacional Big Data\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(5) Seguridad de Big Data\u003c/p\u003e\n\u003cp\u003eEsta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:\u003c/p\u003e\n\u003cp\u003eCiclo de vida de seguridad\u003c/p\u003e\n\u003cp\u003eControl de acceso de grano fino\u003c/p\u003e\n\u003cp\u003eControl de acceso forzado de encriptación\u003c/p\u003e\n\u003cp\u003eEntorno de confianza\u003c/p\u003e\n\u003cp\u003eFADI para la cooperación y la integración de servicios\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSeguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(9) HDFS MapReduce\u003c/p\u003e\n\u003cp\u003eSoluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights\u003c/p\u003e\n\u003cp\u003eSistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos\u003c/p\u003e\n\u003cp\u003e(10) SQL en Hadoop\u003c/p\u003e\n\u003cp\u003eHerramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL\u003c/p\u003e\n\u003cp\u003eSQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)\u003c/p\u003e\n\u003cp\u003e(11) Búsqueda distribuida\u003c/p\u003e\n\u003cp\u003eejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch\u003c/p\u003e\n\u003cp\u003eElastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.\u003c/p\u003e\n\u003cp\u003e(12) Transmisión de mensajes\u003c/p\u003e\n\u003cp\u003eKafka, JMS, AMQ\u003c/p\u003e\n\u003cp\u003eTransmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes\u003c/p\u003e\n\u003cp\u003e(13) Procesamiento de flujo de eventos\u003c/p\u003e\n\u003cp\u003eApache Storm\u003c/p\u003e\n\u003cp\u003eStorm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo \u0026ldquo;al menos una vez semántica\u0026rdquo; a favor de la velocidad.\u003c/p\u003e\n\u003cp\u003e(14) procesamiento de eventos complejos\u003c/p\u003e\n\u003cp\u003eSpark, Flink\u003c/p\u003e\n\u003cp\u003eProcesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.\u003c/p\u003e\n\u003cp\u003e(15)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de Big Data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(16)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDistribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los \u0026ldquo;tres grandes\u0026rdquo; (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(18)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea \u0026ldquo;más fácil\u0026rdquo; de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de Big Data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(19)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePara codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de Big Data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp align\u003d\"center\"\u003e\n  \u003cimg src\u003d\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\"\u003e\n\u003c/p\u003e\n\u003ch3\u003eMejores prácticas para avanzar en el ecosistema de Big Data\u003c/h3\u003e\n\u003cp\u003eSí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de Big Data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso\u003c/h2\u003e\n\u003cp\u003eNo te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de Big Data citado por los encuestados fue \u0026ldquo;determinar cómo obtener valor del Big Data\u0026rdquo; (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización\u003c/h2\u003e\n\u003cp\u003eComo se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 3: Piensa preparado para el futuro\u003c/h2\u003e\n\u003cp\u003eYa lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es \u0026ldquo;a prueba de futuro\u0026rdquo; o \u0026ldquo;preparada para el futuro\u0026rdquo; a través de una arquitectura modular y \u0026ldquo;conectable\u0026rdquo;. Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://www.datameer.com/blog/big-data-ecosystem/\" title\u003d\"Datameer\"\u003eDatameer\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eEl Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.\u003c/p\u003e\n\u003cp\u003eDe acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConsistencia: cada cliente siempre tiene la misma visión de los datos.\u003c/li\u003e\n\u003cli\u003eDisponibilidad: todos los clientes siempre pueden leer y escribir.\u003c/li\u003e\n\u003cli\u003eTolerancia de partición: el sistema funciona bien en las particiones de red física.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href\u003d\"http://mattturck.com/bigdata2018/\" title\u003d\"mattturck 2018\"\u003emattturck 2018\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"http://mattturck.com/bigdata2017/\" title\u003d\"mattturck 2017\"\u003emattturck 2017\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eotros recursos a revisar:\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf\"\u003e1\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://www.nature.com/articles/527S16a\"\u003e2\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf\"\u003e3\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf\"\u003e4\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#\"\u003e5!\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://interset.com/2018/01/23/big-data-tech-explained-part-1/\"\u003e6\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://interset.com/2018/01/30/big-data-tech-part-2/\"\u003e7\u003c/a\u003e\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530217105158_-973283094",
      "id": "20180628-201825_726803088",
      "dateCreated": "Jun 28, 2018 8:18:25 PM",
      "dateStarted": "Jul 6, 2018 11:48:23 PM",
      "dateFinished": "Jul 6, 2018 11:48:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1530217201740_-786725850",
      "id": "20180628-202001_1451533712",
      "dateCreated": "Jun 28, 2018 8:20:01 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "El ecosistema de Big Data",
  "id": "2DK27K9S6",
  "angularObjects": {
    "2CHS8UYQQ:shared_process": [],
    "2C8A4SZ9T_livy2:shared_process": [],
    "2CK8A9MEG:shared_process": [],
    "2CKAY1A8Y:shared_process": [],
    "2C4U48MY3_spark2:shared_process": [],
    "2CKEKWY8Z:shared_process": []
  },
  "config": {},
  "info": {}
}