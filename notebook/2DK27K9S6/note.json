{"paragraphs":[{"text":"Big Data no es solo un problema de base de datos o una herramienta en particular, es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. En realidad, Big Data es \"un combustible\" de todos estos procesos, fuentes, objetivos y resultados. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.\n\nTal como está hoy, el ecosistema de big data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del big data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas de la tecnología. Resulta sumamente dificil describir todas las tecnologias que componen el ecosistema de big data, es por esto que dichas tecnologias han sido divididas en diferentes catergorias y estas a su vez se han llegado a dividir en areas mas especificas. A continuación se definiran una serie de componentes que abordan los diferentes aspectos del ecosistema de Big Data:\n\n---\n\n#### Tipos de datos\n\nLas diferentes etapas de la transformación de Big Data requieren y utilizan diferentes estructuras de datos, modelos y formatos.\n\n<p>\n<img align=\"left\" width=\"700\" height=\"350\" src=\"https://dtflaneur.files.wordpress.com/2013/02/svuns.png?w=700\">\n</p>\n\n\n* Datos estructurados: Los datos estructurados se refieren a todos los datos que se pueden almacenar una base de datos relacional, en tablas con filas y columnas. Tienen una clave relacional y se pueden mapear fácilmente en campos prediseñados. La informcaión estructurada es relativamente simple de ingresar, almacenar, consultar y analizar, pero debe estar estrictamente definida en términos de nombre y tipo de campo.\n\n* Datos no estructurados: Los datos no estructurados pueden tener su propia estructura interna, pero no se ajustan perfectamente a una hoja de cálculo o base de datos. Hoy más del 80% de los datos generados no están estructurados. El desafío fundamental de las fuentes de datos no estructurados es que son difíciles de descifrar, comprender y preparar para el uso analítico\n\n* Datos semiestructurados: Los datos semiestructurados son información que no reside en una base de datos relacional pero que tiene algunas propiedades organizacionales que hacen que sea más fácil de analizar. Ejemplos de información semiestructurada: CSV, XML y JSON son documentos semiestructurados, las bases de datos NoSQL se consideran semiestructuradas. Los datos semiestructurados son una forma de datos estructurados que no se ajusta a la estructura formal de los modelos de datos asociados con bases de datos relacionales u otras formas de tablas de datos, pero que contienen etiquetas u otros marcadores para separar elementos semánticos y aplicar jerarquías de registros y campos dentro de los datos.\n\n---\n\n#### Motores de ejecución\n\n<p>\n<img align=\"left\" width=\"200\" height=\"200\" src=\"https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/05/hadoop-120x28.jpeg\">\n</p>\n\n<img align=\"right\" width=\"100\" height=\"100\" src=\"https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/05/hadoop-120x28.jpeg\">\n+ Hadoop:Es un framework de código abierto de Apache escrito en java que permite el procesamiento distribuido de grandes conjuntos de datos en grupos de computadoras utilizando modelos de programación simples. Una aplicación que trabaja en Hadoop funciona en un entorno que proporciona almacenamiento distribuido y computación entre clusters de computadoras. Hadoop está diseñado para escalar desde un único servidor a miles de máquinas, cada una de las cuales ofrece cómputo y almacenamiento local.\n    \n    + HDFS: Es un sistema de archivos distribuidos y tolerante a fallas, diseñado para convertir un grupo de servidores estándar de la industria en un grupo de almacenamiento de escalamiento masivo. Desarrollado específicamente para cargas de trabajo de procesamiento de datos a gran escala donde la escalabilidad, la flexibilidad y el rendimiento son críticos, HDFS acepta datos en cualquier formato independientemente del esquema, optimiza la transmisión de ancho de banda alto y escala a despliegues comprobados de 100PB y más.\n    \n    + Hadoop MapReduce MapReduce es el corazón de Apache Hadoop. Es este paradigma de programación que permite una escalabilidad masiva en cientos o miles de servidores en un clúster de Hadoop, permite escribir fácilmente aplicaciones que procesan grandes cantidades de datos en paralelo en grandes clusters (miles de nodos) de hardware básico de una manera confiable y tolerante a fallas. El término MapReduce en realidad se refiere a las siguientes dos tareas diferentes que realizan los programas de Hadoop:\n    \n    + YARN: Es un framework para la programación de trabajos y la administración de recursos del clúster. Proporciona administración de recursos de código abierto para Hadoop, por lo que puede ir más allá del procesamiento por lotes y abrir sus datos a un conjunto diverso de cargas de trabajo, que incluyen SQL interactivo, modelado avanzado y transmisión en tiempo real.\n\n+ Tez: Apache Tez es un framework extensible para la construcción de lotes de alto rendimiento y aplicaciones interactivas de procesamiento de datos, coordinado por YARN en Apache Hadoop. Tez mejora el paradigma MapReduce al mejorar drásticamente su velocidad, al tiempo que mantiene la capacidad de MapReduce para escalar a petabytes de datos.\n\n+ Apache Spark: es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos. Con Spark funcionando en Apache Hadoop YARN, los desarrolladores de todo el mundo ahora pueden crear aplicaciones para explotar el poder de Spark, obtener ideas y enriquecer sus cargas de trabajo de ciencia de datos dentro de un solo conjunto de datos compartido en Hadoop.\n\n\n\ny hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.\n\n\n(2) Administración Big Data\n\nLas tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.\n\n* Ciclo de vida de Big Data (Gestión)\n* Transformación y puesta en escena\n* Origen, Limpieza, Archivado\n\n(3) Analítica Big Data y herramientas\n\nAdemás de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:\n\nServicios de cluster\n\nServicios y herramientas relacionados con Hadoop\n\nHerramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)\n\nBases de datos / Servidores SQL, NoSQL\n\nBases de datos MPP (Massively Parallel Processing)\n\nActualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.\n\n* Aplicaciones Big Data\n* Objetivo de uso, presentación, visualización\n\n(4) Infraestructura Big Data\n\nLos servicios y componentes generales de la infraestructura de Big Data incluyen:\n\nHerramientas administración de Big Data\n\nRegistros, indexación/búsqueda, semántica, espacios de nombres\n\nInfraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)\n\nEntorno colaborativo (gestión de grupos)\n\n* Almacenamiento, red de procesamiento (HPC)\n* Red de sensores, dispositivos accionables\n* Soporte operacional Big Data\n\n(5) Seguridad de Big Data\n\nEsta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:\n\nCiclo de vida de seguridad\n\nControl de acceso de grano fino\n\nControl de acceso forzado de encriptación\n\nEntorno de confianza\n\nFADI para la cooperación y la integración de servicios\n\n* Seguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables\n\n(6) Bases de datos relacionales:\n\nComo por ejemplo MSFT SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.\n\nEsquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL.\n\n(7) Base de datos analíticas\n\ncomo Columnar, In-Memory, MPP, OLAP Teradata, Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica\n\nEsquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados.\n\n(8) Bases de datos NoSQL\n\ncomo MongoDB, HBase, Cassandra, MarkLogic, Couchbase\n\nEl diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda.\n\n(9) HDFS MapReduce\n\nSoluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights\n\nSistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos\n\n(10) SQL en Hadoop\n\nHerramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL\n\nSQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)\n\n(11) Búsqueda distribuida\n\nejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch\n\nElastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.\n\n(12) Transmisión de mensajes\n\nKafka, JMS, AMQ\n\nTransmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes\n\n(13) Procesamiento de flujo de eventos\n\nApache Storm\n\nStorm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo \"al menos una vez semántica\" a favor de la velocidad.\n\n(14) procesamiento de eventos complejos\n\nSpark, Flink\n\nProcesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.\n\n(15) \n\n* BI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de big data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.\n\n(16)\n* Distribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los \"tres grandes\" (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.\n\n\n(18)\n* SQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea \"más fácil\" de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de big data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.\n\n(19)\n* Para codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de big data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.\n\n<p align=\"center\">\n  <img src=\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\">\n \n</p>\n\n### Mejores prácticas para avanzar en el ecosistema de Big Data\n\nSí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de big data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.\n\n## Big Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso\n\nNo te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de big data citado por los encuestados fue \"determinar cómo obtener valor del Big Data\" (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.\n\n## Big Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización\n\nComo se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.\n\n## Big Data Ecosystem Best Practice # 3: Piensa preparado para el futuro\n\nYa lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es \"a prueba de futuro\" o \"preparada para el futuro\" a través de una arquitectura modular y \"conectable\". Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.\n\n\n\n[Datameer](https://www.datameer.com/blog/big-data-ecosystem/ \"Datameer\")\n\n\nEl Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.\n\nDe acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:\n\n* Consistencia: cada cliente siempre tiene la misma visión de los datos.\n* Disponibilidad: todos los clientes siempre pueden leer y escribir.\n* Tolerancia de partición: el sistema funciona bien en las particiones de red física.\n\n\n[mattturck 2018](http://mattturck.com/bigdata2018/ \"mattturck 2018\")\n[mattturck 2017](http://mattturck.com/bigdata2017/ \"mattturck 2017\")\n\n\notros recursos a revisar:\n\n[1](https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf)\n[2](https://www.nature.com/articles/527S16a)\n[3](http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf)\n[4](https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf)\n[5!](https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#)\n[6](https://interset.com/2018/01/23/big-data-tech-explained-part-1/)\n[7](https://interset.com/2018/01/30/big-data-tech-part-2/)","user":"anonymous","dateUpdated":"2018-07-05T20:08:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":true,"language":"markdown"},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Big Data no es solo un problema de base de datos o una herramienta en particular, es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. En realidad, Big Data es &ldquo;un combustible&rdquo; de todos estos procesos, fuentes, objetivos y resultados. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.</p>\n<p>Tal como está hoy, el ecosistema de big data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del big data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas de la tecnología. Resulta sumamente dificil describir todas las tecnologias que componen el ecosistema de big data, es por esto que dichas tecnologias han sido divididas en diferentes catergorias y estas a su vez se han llegado a dividir en areas mas especificas. A continuación se definiran una serie de componentes que abordan los diferentes aspectos del ecosistema de Big Data:</p>\n<hr />\n<h4>Tipos de datos</h4>\n<p>Las diferentes etapas de la transformación de Big Data requieren y utilizan diferentes estructuras de datos, modelos y formatos.</p>\n<p>\n<img align=\"left\" width=\"700\" height=\"350\" src=\"https://dtflaneur.files.wordpress.com/2013/02/svuns.png?w=700\">\n</p>\n<ul>\n<li><p>Datos estructurados: Los datos estructurados se refieren a todos los datos que se pueden almacenar una base de datos relacional, en tablas con filas y columnas. Tienen una clave relacional y se pueden mapear fácilmente en campos prediseñados. La informcaión estructurada es relativamente simple de ingresar, almacenar, consultar y analizar, pero debe estar estrictamente definida en términos de nombre y tipo de campo.</p>\n</li>\n<li><p>Datos no estructurados: Los datos no estructurados pueden tener su propia estructura interna, pero no se ajustan perfectamente a una hoja de cálculo o base de datos. Hoy más del 80% de los datos generados no están estructurados. El desafío fundamental de las fuentes de datos no estructurados es que son difíciles de descifrar, comprender y preparar para el uso analítico</p>\n</li>\n<li><p>Datos semiestructurados: Los datos semiestructurados son información que no reside en una base de datos relacional pero que tiene algunas propiedades organizacionales que hacen que sea más fácil de analizar. Ejemplos de información semiestructurada: CSV, XML y JSON son documentos semiestructurados, las bases de datos NoSQL se consideran semiestructuradas. Los datos semiestructurados son una forma de datos estructurados que no se ajusta a la estructura formal de los modelos de datos asociados con bases de datos relacionales u otras formas de tablas de datos, pero que contienen etiquetas u otros marcadores para separar elementos semánticos y aplicar jerarquías de registros y campos dentro de los datos.</p>\n</li>\n</ul>\n<hr />\n<h4>Motores de ejecución</h4>\n<p>\n<img align=\"left\" width=\"200\" height=\"200\" src=\"https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/05/hadoop-120x28.jpeg\">\n</p>\n<p><img align=\"right\" width=\"100\" height=\"100\" src=\"https: //2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2013/05/hadoop-120x28.jpeg\"></p>\n<ul>\n<li><p>Hadoop:Es un framework de código abierto de Apache escrito en java que permite el procesamiento distribuido de grandes conjuntos de datos en grupos de computadoras utilizando modelos de programación simples. Una aplicación que trabaja en Hadoop funciona en un entorno que proporciona almacenamiento distribuido y computación entre clusters de computadoras. Hadoop está diseñado para escalar desde un único servidor a miles de máquinas, cada una de las cuales ofrece cómputo y almacenamiento local.</p>\n<ul>\n<li><p>HDFS: Es un sistema de archivos distribuidos y tolerante a fallas, diseñado para convertir un grupo de servidores estándar de la industria en un grupo de almacenamiento de escalamiento masivo. Desarrollado específicamente para cargas de trabajo de procesamiento de datos a gran escala donde la escalabilidad, la flexibilidad y el rendimiento son críticos, HDFS acepta datos en cualquier formato independientemente del esquema, optimiza la transmisión de ancho de banda alto y escala a despliegues comprobados de 100PB y más.</p>\n</li>\n<li><p>Hadoop MapReduce MapReduce es el corazón de Apache Hadoop. Es este paradigma de programación que permite una escalabilidad masiva en cientos o miles de servidores en un clúster de Hadoop, permite escribir fácilmente aplicaciones que procesan grandes cantidades de datos en paralelo en grandes clusters (miles de nodos) de hardware básico de una manera confiable y tolerante a fallas. El término MapReduce en realidad se refiere a las siguientes dos tareas diferentes que realizan los programas de Hadoop:</p>\n</li>\n<li><p>YARN: Es un framework para la programación de trabajos y la administración de recursos del clúster. Proporciona administración de recursos de código abierto para Hadoop, por lo que puede ir más allá del procesamiento por lotes y abrir sus datos a un conjunto diverso de cargas de trabajo, que incluyen SQL interactivo, modelado avanzado y transmisión en tiempo real.</p>\n</li>\n</ul>\n</li>\n<li><p>Tez: Apache Tez es un framework extensible para la construcción de lotes de alto rendimiento y aplicaciones interactivas de procesamiento de datos, coordinado por YARN en Apache Hadoop. Tez mejora el paradigma MapReduce al mejorar drásticamente su velocidad, al tiempo que mantiene la capacidad de MapReduce para escalar a petabytes de datos.</p>\n</li>\n<li><p>Apache Spark: es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos. Con Spark funcionando en Apache Hadoop YARN, los desarrolladores de todo el mundo ahora pueden crear aplicaciones para explotar el poder de Spark, obtener ideas y enriquecer sus cargas de trabajo de ciencia de datos dentro de un solo conjunto de datos compartido en Hadoop.</p>\n</li>\n</ul>\n<p>y hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.</p>\n<p>(2) Administración Big Data</p>\n<p>Las tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.</p>\n<ul>\n<li>Ciclo de vida de Big Data (Gestión)</li>\n<li>Transformación y puesta en escena</li>\n<li>Origen, Limpieza, Archivado</li>\n</ul>\n<p>(3) Analítica Big Data y herramientas</p>\n<p>Además de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:</p>\n<p>Servicios de cluster</p>\n<p>Servicios y herramientas relacionados con Hadoop</p>\n<p>Herramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)</p>\n<p>Bases de datos / Servidores SQL, NoSQL</p>\n<p>Bases de datos MPP (Massively Parallel Processing)</p>\n<p>Actualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.</p>\n<ul>\n<li>Aplicaciones Big Data</li>\n<li>Objetivo de uso, presentación, visualización</li>\n</ul>\n<p>(4) Infraestructura Big Data</p>\n<p>Los servicios y componentes generales de la infraestructura de Big Data incluyen:</p>\n<p>Herramientas administración de Big Data</p>\n<p>Registros, indexación/búsqueda, semántica, espacios de nombres</p>\n<p>Infraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)</p>\n<p>Entorno colaborativo (gestión de grupos)</p>\n<ul>\n<li>Almacenamiento, red de procesamiento (HPC)</li>\n<li>Red de sensores, dispositivos accionables</li>\n<li>Soporte operacional Big Data</li>\n</ul>\n<p>(5) Seguridad de Big Data</p>\n<p>Esta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:</p>\n<p>Ciclo de vida de seguridad</p>\n<p>Control de acceso de grano fino</p>\n<p>Control de acceso forzado de encriptación</p>\n<p>Entorno de confianza</p>\n<p>FADI para la cooperación y la integración de servicios</p>\n<ul>\n<li>Seguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables</li>\n</ul>\n<p>(6) Bases de datos relacionales:</p>\n<p>Como por ejemplo MSFT SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.</p>\n<p>Esquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL.</p>\n<p>(7) Base de datos analíticas</p>\n<p>como Columnar, In-Memory, MPP, OLAP Teradata, Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica</p>\n<p>Esquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados.</p>\n<p>(8) Bases de datos NoSQL</p>\n<p>como MongoDB, HBase, Cassandra, MarkLogic, Couchbase</p>\n<p>El diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda.</p>\n<p>(9) HDFS MapReduce</p>\n<p>Soluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights</p>\n<p>Sistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos</p>\n<p>(10) SQL en Hadoop</p>\n<p>Herramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL</p>\n<p>SQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)</p>\n<p>(11) Búsqueda distribuida</p>\n<p>ejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch</p>\n<p>Elastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.</p>\n<p>(12) Transmisión de mensajes</p>\n<p>Kafka, JMS, AMQ</p>\n<p>Transmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes</p>\n<p>(13) Procesamiento de flujo de eventos</p>\n<p>Apache Storm</p>\n<p>Storm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo &ldquo;al menos una vez semántica&rdquo; a favor de la velocidad.</p>\n<p>(14) procesamiento de eventos complejos</p>\n<p>Spark, Flink</p>\n<p>Procesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.</p>\n<p>(15)</p>\n<ul>\n<li>BI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de big data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.</li>\n</ul>\n<p>(16)</p>\n<ul>\n<li>Distribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los &ldquo;tres grandes&rdquo; (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.</li>\n</ul>\n<p>(18)</p>\n<ul>\n<li>SQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea &ldquo;más fácil&rdquo; de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de big data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.</li>\n</ul>\n<p>(19)</p>\n<ul>\n<li>Para codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de big data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.</li>\n</ul>\n<p align=\"center\">\n  <img src=\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\">\n\n</p>\n<h3>Mejores prácticas para avanzar en el ecosistema de Big Data</h3>\n<p>Sí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de big data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.</p>\n<h2>Big Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso</h2>\n<p>No te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de big data citado por los encuestados fue &ldquo;determinar cómo obtener valor del Big Data&rdquo; (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.</p>\n<h2>Big Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización</h2>\n<p>Como se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.</p>\n<h2>Big Data Ecosystem Best Practice # 3: Piensa preparado para el futuro</h2>\n<p>Ya lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es &ldquo;a prueba de futuro&rdquo; o &ldquo;preparada para el futuro&rdquo; a través de una arquitectura modular y &ldquo;conectable&rdquo;. Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.</p>\n<p><a href=\"https://www.datameer.com/blog/big-data-ecosystem/\" title=\"Datameer\">Datameer</a></p>\n<p>El Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.</p>\n<p>De acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:</p>\n<ul>\n<li>Consistencia: cada cliente siempre tiene la misma visión de los datos.</li>\n<li>Disponibilidad: todos los clientes siempre pueden leer y escribir.</li>\n<li>Tolerancia de partición: el sistema funciona bien en las particiones de red física.</li>\n</ul>\n<p><a href=\"http://mattturck.com/bigdata2018/\" title=\"mattturck 2018\">mattturck 2018</a>\n<br  /><a href=\"http://mattturck.com/bigdata2017/\" title=\"mattturck 2017\">mattturck 2017</a></p>\n<p>otros recursos a revisar:</p>\n<p><a href=\"https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf\">1</a>\n<br  /><a href=\"https://www.nature.com/articles/527S16a\">2</a>\n<br  /><a href=\"http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf\">3</a>\n<br  /><a href=\"https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf\">4</a>\n<br  /><a href=\"https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#\">5!</a>\n<br  /><a href=\"https://interset.com/2018/01/23/big-data-tech-explained-part-1/\">6</a>\n<br  /><a href=\"https://interset.com/2018/01/30/big-data-tech-part-2/\">7</a></p>\n"}]},"apps":[],"jobName":"paragraph_1530217105158_-973283094","id":"20180628-201825_726803088","dateCreated":"2018-06-28T20:18:25+0000","dateStarted":"2018-07-05T20:07:57+0000","dateFinished":"2018-07-05T20:07:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:101"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":true,"language":"markdown"},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1530217201740_-786725850","id":"20180628-202001_1451533712","dateCreated":"2018-06-28T20:20:01+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:102"}],"name":"El ecosistema de Big Data","id":"2DK27K9S6","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2CKAY1A8Y:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}