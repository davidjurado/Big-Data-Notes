{
  "paragraphs": [
    {
      "text": "####El ecosistema de Big Data es demasiado grande\n\n\nBig Data no es solo un problema de base de datos o hadoop, a pesar de que constituyen las principales tecnologías y componentes para el procesamiento de datos a gran escala y el análisis de datos. Es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. En realidad, Big Data es \"un combustible\" de todos estos procesos, fuentes, objetivos y resultados. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.\n\nTal como está hoy, el ecosistema de big data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del big data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas en la pila de tecnología. Resulta sumamente dificil describir todas las tecnologias que componen el ecosistema de big data, es por esto que dichas tecnologias han sido divididas en diferentes catergorias y estas a su vez se han llegado a dividir en areas mas especificas. A continuación se definiran una serie de componentes que abordan los diferentes aspectos del ecosistema de Big Data:\n\n(1) Modelos de datos, estructuras, tipos: Las diferentes etapas de la transformación de Big Data requerirán y utilizarán diferentes estructuras de datos, modelos y formatos, incluida también la posibilidad de procesar datos estructurados y no estructurados.\nSe pueden definir los siguientes tipos de datos:\n\n(a) datos descritos a través de un modelo de datos formal\n(b) datos descritos a través de una gramática formalizada\n(c) datos descritos a través de un formato estándar\n(d) datos textuales o binarios arbitrarios\n\n(2) Administración Big Data\n\nLas tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.\n\n* Ciclo de vida de Big Data (Gestión)\n* Transformación y puesta en escena\n* Origen, Limpieza, Archivado\n\n(3) Analítica Big Data y herramientas\n\nAdemás de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:\n\nServicios de cluster\n\nServicios y herramientas relacionados con Hadoop\n\nHerramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)\n\nBases de datos / Servidores SQL, NoSQL\n\nBases de datos MPP (Massively Parallel Processing)\n\nActualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.\n\n* Aplicaciones Big Data\n* Objetivo de uso, presentación, visualización\n\n(4) Infraestructura Big Data\n\nLos servicios y componentes generales de la infraestructura de Big Data incluyen:\n\nHerramientas administración de Big Data\n\nRegistros, indexación/búsqueda, semántica, espacios de nombres\n\nInfraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)\n\nEntorno colaborativo (gestión de grupos)\n\n* Almacenamiento, red de procesamiento (HPC)\n* Red de sensores, dispositivos accionables\n* Soporte operacional Big Data\n\n(5) Seguridad de Big Data\n\nEsta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:\n\nCiclo de vida de seguridad\n\nControl de acceso de grano fino\n\nControl de acceso forzado de encriptación\n\nEntorno de confianza\n\nFADI para la cooperación y la integración de servicios\n\n* Seguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables\n\n(6) Bases de datos relacionales:\n\nComo por ejemplo MSFT SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.\n\nEsquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL.\n\n(7) Base de datos analíticas\n\ncomo Columnar, In-Memory, MPP, OLAP Teradata, Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica\n\nEsquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados.\n\n(8) Bases de datos NoSQL\n\ncomo MongoDB, HBase, Cassandra, MarkLogic, Couchbase\n\nEl diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda.\n\n(9) HDFS MapReduce\n\nSoluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights\n\nSistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos\n\n(10) SQL en Hadoop\n\nHerramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL\n\nSQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)\n\n(11) Búsqueda distribuida\n\nejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch\n\nElastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.\n\n(12) Transmisión de mensajes\n\nKafka, JMS, AMQ\n\nTransmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes\n\n(13) Procesamiento de flujo de eventos\n\nApache Storm\n\nStorm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo \"al menos una vez semántica\" a favor de la velocidad.\n\n(14) procesamiento de eventos complejos\n\nSpark, Flink\n\nProcesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.\n\n(15) \n\n* BI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de big data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.\n\n(16)\n* Distribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los \"tres grandes\" (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.\n\n(17)\n* Motores de ejecución: y hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.\n\n(18)\n* SQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea \"más fácil\" de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de big data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.\n\n(19)\n* Para codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de big data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.\n\n\u003cp align\u003d\"center\"\u003e\n  \u003cimg src\u003d\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\"\u003e\n \n\u003c/p\u003e\n\n### Mejores prácticas para avanzar en el ecosistema de Big Data\n\nSí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de big data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.\n\n## Big Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso\n\nNo te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de big data citado por los encuestados fue \"determinar cómo obtener valor del Big Data\" (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.\n\n## Big Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización\n\nComo se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.\n\n## Big Data Ecosystem Best Practice # 3: Piensa preparado para el futuro\n\nYa lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es \"a prueba de futuro\" o \"preparada para el futuro\" a través de una arquitectura modular y \"conectable\". Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.\n\n\n\n[Datameer](https://www.datameer.com/blog/big-data-ecosystem/ \"Datameer\")\n\n\nEl Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.\n\nDe acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:\n\n* Consistencia: cada cliente siempre tiene la misma visión de los datos.\n* Disponibilidad: todos los clientes siempre pueden leer y escribir.\n* Tolerancia de partición: el sistema funciona bien en las particiones de red física.\n\n\n[mattturck 2018](http://mattturck.com/bigdata2018/ \"mattturck 2018\")\n[mattturck 2017](http://mattturck.com/bigdata2017/ \"mattturck 2017\")\n\n\notros recursos a revisar:\n\n[1](https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf)\n[2](https://www.nature.com/articles/527S16a)\n[3](http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf)\n[4](https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf)\n[5!](https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#)\n[6](https://interset.com/2018/01/23/big-data-tech-explained-part-1/)\n[7](https://interset.com/2018/01/30/big-data-tech-part-2/)",
      "user": "anonymous",
      "dateUpdated": "Jul 4, 2018 9:56:25 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "editOnDblClick": true,
          "language": "markdown"
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch4\u003eEl ecosistema de Big Data es demasiado grande\u003c/h4\u003e\n\u003cp\u003eBig Data no es solo un problema de base de datos o hadoop, a pesar de que constituyen las principales tecnologías y componentes para el procesamiento de datos a gran escala y el análisis de datos. Es todo el complejo de componentes para almacenar, procesar, visualizar y entregar resultados a las aplicaciones de destino. En realidad, Big Data es \u0026ldquo;un combustible\u0026rdquo; de todos estos procesos, fuentes, objetivos y resultados. Todo este complejo interrelacionado se puede definir como el ecosistema de Big Data que se ocupa de la evolución de los datos, los modelos y la infraestructura requerida durante todo el ciclo de vida de Big Data.\u003c/p\u003e\n\u003cp\u003eTal como está hoy, el ecosistema de big data es demasiado grande, complejo y redundante. Es un mercado confuso para las personas y empresas que han aceptado la idea del big data, pero luego tropiezan cuando se enfrentan a demasiadas decisiones en numerosas capas en la pila de tecnología. Resulta sumamente dificil describir todas las tecnologias que componen el ecosistema de big data, es por esto que dichas tecnologias han sido divididas en diferentes catergorias y estas a su vez se han llegado a dividir en areas mas especificas. A continuación se definiran una serie de componentes que abordan los diferentes aspectos del ecosistema de Big Data:\u003c/p\u003e\n\u003cp\u003e(1) Modelos de datos, estructuras, tipos: Las diferentes etapas de la transformación de Big Data requerirán y utilizarán diferentes estructuras de datos, modelos y formatos, incluida también la posibilidad de procesar datos estructurados y no estructurados.\n\u003cbr  /\u003eSe pueden definir los siguientes tipos de datos:\u003c/p\u003e\n\u003cp\u003e(a) datos descritos a través de un modelo de datos formal\n\u003cbr  /\u003e(b) datos descritos a través de una gramática formalizada\n\u003cbr  /\u003e(c) datos descritos a través de un formato estándar\n\u003cbr  /\u003e(d) datos textuales o binarios arbitrarios\u003c/p\u003e\n\u003cp\u003e(2) Administración Big Data\u003c/p\u003e\n\u003cp\u003eLas tecnologías Big Data deben adoptar métodos de descubrimiento científico que incluyan la mejora iterativa del modelo y la recopilación de datos mejorados, la reutilización de los datos recopilados con un modelo mejorado.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCiclo de vida de Big Data (Gestión)\u003c/li\u003e\n\u003cli\u003eTransformación y puesta en escena\u003c/li\u003e\n\u003cli\u003eOrigen, Limpieza, Archivado\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(3) Analítica Big Data y herramientas\u003c/p\u003e\n\u003cp\u003eAdemás de los servicios generales de infraestructura en la nube (almacenamiento, cómputo, administración de infraestructura / VM) se requerirán las siguientes aplicaciones y servicios específicos para soportar Big Data y otras aplicaciones centradas en datos:\u003c/p\u003e\n\u003cp\u003eServicios de cluster\u003c/p\u003e\n\u003cp\u003eServicios y herramientas relacionados con Hadoop\u003c/p\u003e\n\u003cp\u003eHerramientas especializadas de análisis de datos (registros, eventos, extracción de datos, etc.)\u003c/p\u003e\n\u003cp\u003eBases de datos / Servidores SQL, NoSQL\u003c/p\u003e\n\u003cp\u003eBases de datos MPP (Massively Parallel Processing)\u003c/p\u003e\n\u003cp\u003eActualmente, los principales proveedores de servicios en la nube ofrecen herramientas de análisis Big Data, como Amazon Elastic MapReduce y Dynamo, Microsoft Azure HDInsight, IBM Big Data Analytics. Las herramientas escalables de Hadoop y de herramientas de análisis de datos son ofrecidas por pocas compañías que se posicionan como compañías de Big Data como Cloudera, y algunas otras.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAplicaciones Big Data\u003c/li\u003e\n\u003cli\u003eObjetivo de uso, presentación, visualización\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(4) Infraestructura Big Data\u003c/p\u003e\n\u003cp\u003eLos servicios y componentes generales de la infraestructura de Big Data incluyen:\u003c/p\u003e\n\u003cp\u003eHerramientas administración de Big Data\u003c/p\u003e\n\u003cp\u003eRegistros, indexación/búsqueda, semántica, espacios de nombres\u003c/p\u003e\n\u003cp\u003eInfraestructura de seguridad (control de acceso, cumplimiento de políticas, confidencialidad, confianza, disponibilidad, privacidad)\u003c/p\u003e\n\u003cp\u003eEntorno colaborativo (gestión de grupos)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAlmacenamiento, red de procesamiento (HPC)\u003c/li\u003e\n\u003cli\u003eRed de sensores, dispositivos accionables\u003c/li\u003e\n\u003cli\u003eSoporte operacional Big Data\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(5) Seguridad de Big Data\u003c/p\u003e\n\u003cp\u003eEsta sección trata sobre el Big Data Security Framework que respalda un nuevo paradigma de seguridad centrada en datos. Los siguientes componentes están incluidos:\u003c/p\u003e\n\u003cp\u003eCiclo de vida de seguridad\u003c/p\u003e\n\u003cp\u003eControl de acceso de grano fino\u003c/p\u003e\n\u003cp\u003eControl de acceso forzado de encriptación\u003c/p\u003e\n\u003cp\u003eEntorno de confianza\u003c/p\u003e\n\u003cp\u003eFADI para la cooperación y la integración de servicios\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSeguridad de datos en estado de reposo, en movimiento, entornos de procesamiento confiables\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(6) Bases de datos relacionales:\u003c/p\u003e\n\u003cp\u003eComo por ejemplo MSFT SQL Server, Oracle, MySQL , PostGreSQL, IBM DB2.\u003c/p\u003e\n\u003cp\u003eEsquema estructurado de tablas que contienen filas y columnas de datos que enfatizan la integridad y la coherencia sobre la velocidad y la escala. Datos estructurados a los que se accede con el lenguaje de consulta SQL.\u003c/p\u003e\n\u003cp\u003e(7) Base de datos analíticas\u003c/p\u003e\n\u003cp\u003ecomo Columnar, In-Memory, MPP, OLAP Teradata, Oracle Exadata, IBM Netezza, EMC Greenplum, Vertica\u003c/p\u003e\n\u003cp\u003eEsquema estructurado de tablas que contiene filas y columnas de datos que ofrecen velocidad y escalabilidad mejoradas en RDBMS, pero que aún se limitan a datos estructurados.\u003c/p\u003e\n\u003cp\u003e(8) Bases de datos NoSQL\u003c/p\u003e\n\u003cp\u003ecomo MongoDB, HBase, Cassandra, MarkLogic, Couchbase\u003c/p\u003e\n\u003cp\u003eEl diseño sin esquema permite una ingesta rápida o continua a escala. Buena opción de almacenamiento para alto rendimiento, bajos requisitos de latencia de aplicaciones de transmisión para vistas de datos en tiempo real. Visto como un componente clave de la arquitectura Lambda.\u003c/p\u003e\n\u003cp\u003e(9) HDFS MapReduce\u003c/p\u003e\n\u003cp\u003eSoluciones como Cloudera, Hortonworks, MapR, Pivotal, Amazon EMR, Hitachi HSP, MSFT HDInsights\u003c/p\u003e\n\u003cp\u003eSistema de archivos distribuidos Hadoop diseñado para distribuir y replicar bloques de archivos escalados horizontalmente a través de múltiples nodos de datos de productos. La rogramación de MapReduce requiere calcular los datos para el procesamiento por lotes de grandes volúmenes de datos\u003c/p\u003e\n\u003cp\u003e(10) SQL en Hadoop\u003c/p\u003e\n\u003cp\u003eHerramientas como Apache Hive, Apache Drill/Phoenix, Hortonworks Hive on Tez, Cloudera Impala, Pivotal HawQ, Spark SQL\u003c/p\u003e\n\u003cp\u003eSQL fue diseñado para datos estructurados. Los archivos Hadoop pueden contener datos anidados, datos variables y datos sin esquema. Un motor SQL-on-Hadoop debe poder traducir todas estas formas de datos a datos relacionales planos y optimizar consultas (Impala / Drill)\u003c/p\u003e\n\u003cp\u003e(11) Búsqueda distribuida\u003c/p\u003e\n\u003cp\u003eejm ElasticSearch, Solr(based on Apache Lucene), Amazon CloudSearch\u003c/p\u003e\n\u003cp\u003eElastic Search es escalable a clústeres muy grandes con búsqueda casi en tiempo real. Las demandas de las aplicaciones web en tiempo real requieren resultados de búsqueda casi en tiempo real a medida que los usuarios generan contenido nuevo.\u003c/p\u003e\n\u003cp\u003e(12) Transmisión de mensajes\u003c/p\u003e\n\u003cp\u003eKafka, JMS, AMQ\u003c/p\u003e\n\u003cp\u003eTransmisión en tiempo real que proporciona un alto rendimiento tanto para la publicación como para la suscripción, con un rendimiento constante incluso con muchos terabytes de mensajes almacenados. Diseñado para la transmisión y puede configurar el tamaño del lote para intermediar micro lotes de mensajes\u003c/p\u003e\n\u003cp\u003e(13) Procesamiento de flujo de eventos\u003c/p\u003e\n\u003cp\u003eApache Storm\u003c/p\u003e\n\u003cp\u003eStorm es extremadamente rápido, con la capacidad de procesar más de un millón de mensajes por segundo por nodo. Compromete a la tolerancia a fallas ofreciendo \u0026ldquo;al menos una vez semántica\u0026rdquo; a favor de la velocidad.\u003c/p\u003e\n\u003cp\u003e(14) procesamiento de eventos complejos\u003c/p\u003e\n\u003cp\u003eSpark, Flink\u003c/p\u003e\n\u003cp\u003eProcesamiento complejo de eventos para internet de cosas, sensores y sistemas transaccionales. Una solución de CEP orientada a la agregación se centra en la ejecución de algoritmos en línea como respuesta a datos de eventos que ingresan al sistema. El CEP orientado a la detección se centra en la detección de combinaciones de eventos llamados patrones o situaciones de eventos.\u003c/p\u003e\n\u003cp\u003e(15)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBI / Analytics: en la parte superior de la pila, hay opciones aparentemente interminables. Ya sea que Enterprise BI sea incondicional, retadores de BI 2.0 o jugadores de análisis de big data, la cantidad de proveedores y su posicionamiento similar lo hace realmente difícil para los clientes. Es difícil distinguir entre soluciones, incluso significativamente diferentes, cuando los mensajes y las imágenes son muy similares.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(16)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDistribuciones: baje en la pila y hay mucho para elegir en la capa de distribución de Hadoop y Spark. Ya es bastante difícil que los \u0026ldquo;tres grandes\u0026rdquo; (Cloudera, Hortonworks y MapR) ofrezcan sus propias distribuciones de Hadoop, con Spark integrado. Pero agregue otras ofertas de IBM, y los jugadores de la nube, grandes y pequeños, y las cosas se vuelven un poco locas. Lo que es difícil para el cliente aquí es que el núcleo de estas pilas difieren en su composición y / o tienen diferentes versiones de los mismos componentes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(17)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMotores de ejecución: y hablando de componentes, también tenemos demasiados motores de ejecución. Hadoop cambió de MapReduce a Tez. Entonces Spark se estableció. Y ahora, parece, Apache Flink está esperando en las alas. En el lado de la transmisión, Apache Storm, NiFi, Spark y Kafka, en varias combinaciones, compiten por la atención. Y mientras que el aprendizaje automático de Big Data comenzó con Apache Mahout, parece estar cambiando a Spark MLlib y en otros lugares. Luego están las permutaciones. Por ejemplo, Spark puede ejecutarse en YARN, el administrador de recursos de Hadoop 2.0. Pero no tiene por qué. Y cuando utiliza la oferta Spark basada en la nube de Databricks (la compañía fundada por los creadores de Spark), no es así.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(18)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSQL, conjuntos de datos y flujos: Y mientras SQL se abrió paso en la conversación de Big Data para hacer que todo sea \u0026ldquo;más fácil\u0026rdquo; de usar por los conjuntos de habilidades de aprovechamiento existentes, también hay demasiados SQL en las soluciones de big data. ¿Deberías usar Hive o Spark SQL? Si usa Hive, ¿debería usarlo en MapReduce o Tez? Además, no te olvides de Impala. O HAWQ, Apache Drill, Presto y todos los puentes SQL-on-Hadoop de los grandes proveedores de bases de datos, incluidos Teradata, HP, Microsoft, Oracle e IBM. Ni siquiera profundicemos en el hecho de que el uso de SQL puede ser una antítesis de Hadoop y sus beneficios únicos. Sin embargo, otra capa de confusión. Incluso dentro de una pila bien definida con un pequeño número de componentes, la fragmentación puede ser desenfrenada. En el mundo de Spark, puede usar conjuntos de datos distribuidos (RDD) resistentes, marcos de datos o conjuntos de datos. Y los desarrolladores de Spark pueden usar las nuevas Spark Structured Streams para datos en movimiento. Pero, ¿qué pasa con Kafka Streams? Esos son brillantes y nuevos también.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(19)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePara codificar o no codificar: cuando se trata de lenguajes de programación, ¿debe codificar en R o Python? ¿Qué hay de Scala? Y para el caso, ¿por qué no echarles un hueso a los desarrolladores de empresas y dejarles usar Java e incluso C # para escribir su código de big data? Se puede controlar aquí, pero a costa de autoservicio y permitir que más personas dentro de su organización.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp align\u003d\"center\"\u003e\n  \u003cimg src\u003d\"http://mattturck.com/wp-content/uploads/2018/06/Matt-Turck-FirstMark-Big-Data-Landscape-2018.png\"\u003e\n\n\u003c/p\u003e\n\u003ch3\u003eMejores prácticas para avanzar en el ecosistema de Big Data\u003c/h3\u003e\n\u003cp\u003eSí, las cosas están un poco desordenadas, pero están lejos de ser inútiles. Podemos solucionar este problema y podemos dejar que se destaque el importante valor que el ecosistema de big data ha creado. En Hadoop Summit San José, presenté algunas ideas sobre cómo nosotros, como proveedores, analistas, capitalistas de riesgo y todos los demás que conforman este ecosistema de grandes datos, podemos mejorar la situación. Pero más importante aún, esbocé algunos consejos y trucos para los clientes que actualmente están intentando navegar en estas aguas turbias.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 1: Comience siempre con un caso de uso\u003c/h2\u003e\n\u003cp\u003eNo te vengas vendido por tecnología brillante. En una reciente encuesta de Gartner, el principal desafío de big data citado por los encuestados fue \u0026ldquo;determinar cómo obtener valor del Big Data\u0026rdquo; (58% de los encuestados). ¿Cómo lo remedias? Comience siempre con la definición de su caso de uso, luego trabaje hacia la búsqueda de la tecnología que lo respalde.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 2: Considere el Control vs. Democratización\u003c/h2\u003e\n\u003cp\u003eComo se mencionó anteriormente, puede ser tentador darse a ti mismo / a tu equipo controles de nivel fino con herramientas que te permiten codificar. Pero tenga cuidado con la cantidad de control que realmente necesita: ¿se puede mejorar el mejor servicio al poner los datos en manos de más personas en la organización con herramientas de autoservicio? Busque el equilibrio correcto.\u003c/p\u003e\n\u003ch2\u003eBig Data Ecosystem Best Practice # 3: Piensa preparado para el futuro\u003c/h2\u003e\n\u003cp\u003eYa lo hemos visto La industria se está contrayendo, expandiendo, contrayendo, expandiendo. Es por eso que es increíblemente importante que al evaluar su compra de tecnología, busque señales de que la tecnología en sí misma es \u0026ldquo;a prueba de futuro\u0026rdquo; o \u0026ldquo;preparada para el futuro\u0026rdquo; a través de una arquitectura modular y \u0026ldquo;conectable\u0026rdquo;. Porque, si bien es posible que no desee saltar sobre el próximo nuevo proyecto brillante o estándar, querrá la opción de migrar a él, ya que es prudente hacerlo.\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://www.datameer.com/blog/big-data-ecosystem/\" title\u003d\"Datameer\"\u003eDatameer\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eEl Teorema CAP fue propuesto y presentado por Eric Brewer (Profesor de UC Berkeley / Co-Fundador y Científico Jefe de Inktomi) en el Simposio 2000 sobre Principios de Computación Distribuida (PODC), luego probado por Seth Gilbert y Nancy Lynch de MIT.\u003c/p\u003e\n\u003cp\u003eDe acuerdo con el Teorema, solo dos de los siguientes atributos pueden estar presentes en su solución:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConsistencia: cada cliente siempre tiene la misma visión de los datos.\u003c/li\u003e\n\u003cli\u003eDisponibilidad: todos los clientes siempre pueden leer y escribir.\u003c/li\u003e\n\u003cli\u003eTolerancia de partición: el sistema funciona bien en las particiones de red física.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href\u003d\"http://mattturck.com/bigdata2018/\" title\u003d\"mattturck 2018\"\u003emattturck 2018\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"http://mattturck.com/bigdata2017/\" title\u003d\"mattturck 2017\"\u003emattturck 2017\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eotros recursos a revisar:\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://link.springer.com/content/pdf/10.1007%2Fs10021-016-0075-y.pdf\"\u003e1\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://www.nature.com/articles/527S16a\"\u003e2\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"http://www.uazone.org/demch/worksinprogress/sne-2013-02-techreport-bdaf-draft02.pdf\"\u003e3\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://www.pentahoworld.com/sites/default/files/2017-11/Understanding-the-Big-Data-Technology-Ecosystem-PWorld2017_0.pdf\"\u003e4\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://bigdataecosystem.knowledgent.com/big-data-ecosystem/#\"\u003e5!\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://interset.com/2018/01/23/big-data-tech-explained-part-1/\"\u003e6\u003c/a\u003e\n\u003cbr  /\u003e\u003ca href\u003d\"https://interset.com/2018/01/30/big-data-tech-part-2/\"\u003e7\u003c/a\u003e\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1530217105158_-973283094",
      "id": "20180628-201825_726803088",
      "dateCreated": "Jun 28, 2018 8:18:25 PM",
      "dateStarted": "Jul 4, 2018 9:56:25 PM",
      "dateFinished": "Jul 4, 2018 9:56:25 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1530217201740_-786725850",
      "id": "20180628-202001_1451533712",
      "dateCreated": "Jun 28, 2018 8:20:01 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "El ecosistema de Big Data",
  "id": "2DK27K9S6",
  "angularObjects": {
    "2CHS8UYQQ:shared_process": [],
    "2C8A4SZ9T_livy2:shared_process": [],
    "2CK8A9MEG:shared_process": [],
    "2CKAY1A8Y:shared_process": [],
    "2C4U48MY3_spark2:shared_process": [],
    "2CKEKWY8Z:shared_process": []
  },
  "config": {},
  "info": {}
}