# El ecosistema Big Data en el ambiente Apache

Se mencionaron algunos miembros del ecosistema de Big Data en el anterior [documento](https://github.com/davidjurado/Big-Data-Notes/blob/master/notebook/1.md) . Sin embargo, el ecosistema de Apache es demasiado grande y necesita ser definido por separado, a continuación se mencionan los componentes que conforman el ecosistema Big Data en el ambiente Apache

---

### Herramientas de inserción de datos en HDFS

La mayoría de los datos se originan fuera del clúster de Hadoop. Estas herramientas permiten insertar datos en HDFS.

|Herramienta|Observaciones|
| --------- |  :------------|
Flume |Recopila datos de múltiples fuentes y los coloca en HDFS
Chukwa |Sistema de recopilación de datos
Sqoop |Transfiere datos entre Hadoop y bases de datos relacionales (RDBMS)
Kafka |Sistema distribuido de suscripción y publicación

---

### Frameworks de ejecución

|Herramienta|Observaciones|
| --------- |  :------------|
Map reduce |Framework original de computo distribuido de Hadoop
YARN |Nueva generación de MapReduce, disponible en Hadoop versión 2.0
Weave |Programación YARN simplificada
Cloudera SDK |Programación simplificada de MapReduce
Flink|Flink ofrece las mismas características de Spark pero con una implementación muy diferente

---

### Consulta de datos en HDFS

|Herramienta|Observaciones|
| --------- |  :------------|
Java MapReduce |Mapreduce nativo en Java
Hadoop Streaming |Mapreduce en otros lenguajes (Ruby, Python)
Pig |Pig proporciona un lenguaje de flujo de datos de nivel superior para procesar datos. Los scripts de Pig son mucho más compactos que Java Map Reduce code.
Hive |Hive proporciona una capa SQL sobre HDFS. Los datos se pueden consultar utilizando SQL en lugar de escribir código Java Map Reduce.
Stinger / Tez |Próxima generación de Hive.
Cloudera Search |Búsqueda de texto en HDFS
Impala |Proporciona consultas en tiempo real sobre Big Data. Desarrollado por Cloudera.
Presto |Desarrollado por Facebook, proporciona consultas SQL rápidas sobre Hadoop

---

### SQL en Hadoop / HBase

|Herramienta|Observaciones|
| --------- |  :------------|
Hive |Hive proporciona una capa SQL sobre HDFS. Los datos se pueden consultar utilizando SQL en lugar de escribir código Java Map Reduce.
Stinger / Tez |Próxima generación de Hive.
Impala |Proporciona consultas en tiempo real sobre Big Data. Desarrollado por Cloudera.
Presto |Desarrollado por Facebook, proporciona consultas SQL rápidas sobre Hadoop
Phoenix |Capa SQL sobre HBase. Desarrollado por SalesForce.com.
Spire |Capa SQL sobre HBase. Desarrollado por DrawnToScale.com.
Apache Drill| Análisis interactivo de conjuntos de datos a gran escala.

---

### Consultas en tiempo real

|Herramienta|Observaciones|
| --------- |  :------------|
Apache Drill |Análisis interactivo de conjuntos de datos a gran escala.
Impala |Proporciona consultas en tiempo real sobre Big Data. Desarrollado por Cloudera.

---

## Procesamiento en Streaming

|Herramienta|Observaciones|
| --------- |  :------------|
Storm |Procesamiento de flujo rápido desarrollado por Twitter.
Apache S4 | S4 (Simple Scalable Streaming System) es una plataforma de uso general, distribuible, escalable, parcialmente tolerante a fallas y conectable que permite a los programadores desarrollar fácilmente aplicaciones para procesar flujos continuos e ilimitados de datos.
Samza |Apache Samza es un marco de procesamiento de flujo distribuido. Utiliza Apache Kafka para mensajería y Apache Hadoop YARN para proporcionar tolerancia a fallas, aislamiento de procesador, seguridad y administración de recursos.
Malhar |Plataforma Hadoop nativa, escalable, tolerante a los fallos y con estado completo, desarrollada por DataTorrent

---

### Almacenamiento NoSQL

|Herramienta|Observaciones|
| --------- |  :------------|
HBase |NoSQL construido sobre Hadoop.
Cassandra |Base de datos NoSQL
Redis |Almacenamiento llave/valor
Amazon SimpleDB |Ofrecido por Amazon en su entorno.
Voldermort |Almacén de valores clave distribuido desarrollado por LinkedIn.
Accumulo |Una tienda NoSQL desarrollada por la NSA.
Kudu|sistema de almacenamiento de datos en formato columnar que permite realizar consultas analíticas sobre estos de forma más fácil y con un gran rendimiento. 

### Hadoop en la nube

|Herramienta|Observaciones|
| --------- |  :------------|
Amazon Elastic Map Reduce (EMR) |Hadoop bajo demanda en AWS
Hadoop on Rackspace |Administración de Hadoop en Rackspace
Hadoop on Google Cloud |Hadoop ejecutado en Google Cloud
Whirr |Herramienta para activar y administrar fácilmente los clústeres Hadoop en servicios en la nube como Amazon / RackSpace.

### Herramientas de flujo de trabajo

|Herramienta|Observaciones|
| --------- |  :------------|
Oozie |Orquesta trabajos de MapReduce
Azkaban |Programador de tareas por lotes creado en LinkedIn para ejecutar trabajos de Hadoop. 
Cascading |Marco de aplicación para que los desarrolladores de Java desarrollen sólidas aplicaciones de Data Analytics y Data Management en Apache Hadoop.
Scalding |Biblioteca de Scala que facilita la especificación de trabajos de Hadoop MapReduce. El escaldado se construye encima de Cascading.
Lipstick |Visualización del flujo de trabajo Pig

### Frameworks de serialización

|Herramienta|Observaciones|
| --------- |  :------------|
Avro |Sistema de serialización de datos.
Trevni |Formato de archivo de columna
Protobuf |Biblioteca de serialización popular (no es un proyecto de Hadoop).
Parquet |formato de almacenamiento columnar para Hadoop

### Sistemas de monitoreo

|Herramienta|Observaciones|
| --------- |  :------------|
Hue |Hue es una interfaz web para analizar datos con Apache Hadoop. Puedes ser instalado en cualquier pc con cualquier versión de hadoop. Desarrollado por Cloudera.
Ganglia |Sistema de monitoreo general del host. Hadoop puede publicar métricas en Ganglia.
Open TSDB |Colector de métricas y visualizador.
Nagios |Monitoreo de la infraestructura de TI.

### Aplicaciones y plataformas

|Herramienta|Observaciones|
| --------- |  :------------|
Mahout |Motor de recomendación en la parte superior de Hadoop.
Giraph |Procesamiento rápido de gráficos en la parte superior de Hadoop.
Lily |Lily unifica Apache HBase, Hadoop y Solr en una plataforma de datos interactiva e integrada

### Coordinación Distribuida

|Herramienta|Observaciones|
| --------- |  :------------|
Zookeeper |ZooKeeper es un servicio centralizado para mantener la información de configuración, nombrar y proporcionar sincronización distribuida.
Book keeper |Servicio de registro distribuido basado en ZooKeeper.

### Data Analytics en Hadoop

|Herramienta|Observaciones|
| --------- |  :------------|
R language |Entorno de software para computación y gráficos estadísticos.
RHIPE |Integra R y Hadoop.

### Procesamiento de mensajes distribuidos

|Herramienta|Observaciones|
| --------- |  :------------|
Kafka |Sistema distribuido de suscripción y publicación.
Akka |Sistema de mensajería distribuida con actores.
RabbitMQ |Sistema de mensajería MQ distribuido.

### Herramientas de Business Intelligence (BI)

|Herramienta|Observaciones|
| --------- |  :------------|
Datameer |La compañía se centra en el análisis y la visualización de big data. 
Tableau |Empresa de software que desarrolla productos de visualización de datos interactivos que se enfocan en inteligencia empresarial.
Pentaho |Ofrece un conjunto de programas para generar inteligencia empresarial.
SiSense |Su producto de inteligencia de negocios incluye un dispositivo de respaldo con tecnología integrada en el chip que permite a los usuarios no técnicos unirse y analizar grandes conjuntos de datos de múltiples fuentes
SumoLogic |Permite crear, ejecutar y proteger aplicaciones AWS, Azure, Google Cloud Platform o híbridas, da un servicio analítico de datos de máquina nativo de la nube para administración de registros y mediciones de series de tiempo.

---

### Frameworks basados ​​en YARN

|Herramienta|Observaciones|
| --------- |  :------------|
Samza |Apache Samza es un marco de procesamiento de flujo distribuido. Utiliza Apache Kafka para mensajería y Apache Hadoop YARN para proporcionar tolerancia a fallas, aislamiento de procesador, seguridad y administración de recursos.
Spark |Spark es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos.
Malhar |Plataforma Hadoop nativa, escalable, tolerante a los fallos y con estado completo, desarrollada por DataTorrent
Storm |Procesamiento de flujo rápido desarrollado por Twitter.
Hoya (HBase en YARN) | La herramienta Hoya es una herramienta Java y actualmente está dirigida por CLI.

### Librerias / Frameworks

|Herramienta|Observaciones|
| --------- |  :------------|
Kiji |Crear aplicaciones Big Data en tiempo real en Apache HBase
Elephant Bird |Códigos de compresión y serializadores para Hadoop.
Summing Bird |MapReduce en Storm
Apache Crunch |Líneas simples y eficientes de MapReduce para Hadoop y Spark
Apache DataFu |Trabaja con datos a gran escala en Hadoop. El proyecto se inspiró en la necesidad de bibliotecas estables y bien probadas para la extracción de datos y las estadísticas.
Continuuity |Crea aplicaciones en HBase fácilmente

### Gestión de datos

|Herramienta|Observaciones|
| --------- |  :------------|
Apache Falcon |Gestión de datos, linaje de datos

### Seguridad

|Herramienta|Observaciones|
| --------- |  :------------|
Apache Sentry |Es un sistema altamente modular para proporcionar una autorización basada en funciones de granularidad fina a datos y metadatos almacenados en un clúster Apache Hadoop.
Apache Knox |Es una puerta de enlace API REST para interactuar con clústeres de Hadoop. Knox Gateway proporciona un único punto de acceso para todas las interacciones REST con clústeres de Hadoop.

###  Frameworks de prueba

|Herramienta|Observaciones|
| --------- |  :------------|
MrUnit |Framework de pruebas unitarias para Java MapReduce
PigUnit |Para testear scripts de Pig

### Adicional

|Herramienta|Observaciones|
| --------- |  :------------|
Spark |Spark es un motor rápido de procesamiento de datos en memoria con APIs de desarrollo elegantes y expresivas para permitir a los trabajadores de datos ejecutar de manera eficiente la transmisión, el aprendizaje automático o las cargas de trabajo SQL que requieren un acceso iterativo rápido a los conjuntos de datos.
Shark (Hive on Spark) | Apache shark es un motor de consulta distribuido desarrollado por la comunidad de código abierto. Este motor de consulta se usa principalmente para datos de Hadoop. Proporciona un rendimiento mejorado y resultados analíticos de alta calidad para los usuarios de Hive.